{
  "id": "section_3_4",
  "text": "IV. AREAS OF POLICY ACTION 48. The policy actions described in the following policy areas operationalize the values and principles set out in this Recommendation. The main action is for Member States to put in place effective measures, including, for example, policy frameworks or mechanisms, and to ensure that other stakeholders, such as private sector companies, academic and research institutions, and civil society adhere to them by, among other actions, encouraging all stakeholders to develop human rights, rule of law, democracy, and ethical impact assessment and due diligence tools in line with guidance including the United Nations Guiding Principles on Business and Human Rights. The process for developing such policies or mechanisms should be inclusive of all stakeholders and should take into account the circumstances and priorities of each Member State. UNESCO can be a partner and support Member States in the development as well as monitoring and evaluation of policy mechanisms. 49. UNESCO recognizes that Member States will be at different stages of readiness to implement this Recommendation, in terms of scientific, technological, economic, educational, legal, regulatory, infrastructural, societal, cultural and other dimensions. It is noted that \"readiness\" here is a dynamic status. In order to enable the effective implementation of this Recommendation, UNESCO will therefore: (1) develop a readiness assessment methodology to assist interested Member States in identifying their status at specific moments of their readiness trajectory along a continuum of dimensions; and (2) ensure support for interested Member States in terms of developing a UNESCO methodology for Ethical Impact Assessment (EIA) of AI technologies, sharing of best practices, assessment guidelines and other mechanisms and analytical work. POLICY AREA 1: ETHICAL IMPACT ASSESSMENT 50. Member States should introduce frameworks for impact assessments, such as ethical impact assessment, to identify and assess benefits, concerns and risks of AI systems, as well as appropriate risk prevention, mitigation and monitoring measures, among other assurance mechanisms. Such impact assessments should identify impacts on human rights and fundamental freedoms, in particular but not limited to the rights of marginalized and vulnerable people or people in vulnerable situations, labour rights, the environment and ecosystems and ethical and social implications, and facilitate citizen participation in line with the values and principles set forth in this Recommendation. 51. Member States and private sector companies should develop due diligence and oversight mechanisms to identify, prevent, mitigate and account for how they address the impact of AI systems on the respect for human rights, rule of law and inclusive societies. Member States should also be able to assess the socio-economic impact of AI systems on poverty and ensure that the gap between people living in wealth and poverty, as well as the digital divide among and within countries, are not increased with the massive adoption of AI technologies at present and in the future. In order to do this, in particular, enforceable transparency protocols should be implemented, corresponding to the access to information, including information of public interest held by private entities. Member States, private sector companies and civil society should investigate the sociological and psychological effects of AI-based recommendations on humans in their decision-making autonomy. AI systems identified as potential risks to human rights should be broadly tested by AI actors, including in real-world conditions if needed, as part of the Ethical Impact Assessment, before releasing them in the market. 52. Member States and business enterprises should implement appropriate measures to monitor all phases of an AI system life cycle, including the functioning of algorithms used for decision-making, the data, as well as AI actors involved in the process, especially in public services and where direct end-user interaction is needed, as part of ethical impact assessment. Member States' human rights law obligations should form part of the ethical aspects of AI system assessments. 53. Governments should adopt a regulatory framework that sets out a procedure, particularly for public authorities, to carry out ethical impact assessments on AI systems to predict consequences, mitigate risks, avoid harmful consequences, facilitate citizen participation and address societal challenges. The assessment should also establish appropriate oversight mechanisms, including auditability, traceability and explainability, which enable the assessment of algorithms, data and design processes, as well as include external review of AI systems. Ethical impact assessments should be transparent and open to the public, where appropriate. Such assessments should also be multidisciplinary, multi-stakeholder, multicultural, pluralistic and inclusive. The public authorities should be required to monitor the AI systems implemented and/or deployed by those authorities by introducing appropriate mechanisms and tools. POLICY AREA 2: ETHICAL GOVERNANCE AND STEWARDSHIP 54. Member States should ensure that AI governance mechanisms are inclusive, transparent, multidisciplinary, multilateral (this includes the possibility of mitigation and redress of harm across borders) and multi-stakeholder. In particular, governance should include aspects of anticipation, and effective protection, monitoring of impact, enforcement and redress. 55. Member States should ensure that harms caused through AI systems are investigated and redressed, by enacting strong enforcement mechanisms and remedial actions, to make certain that human rights and fundamental freedoms and the rule of law are respected in the digital world and in the physical world. Such mechanisms and actions should include remediation mechanisms provided by private and public sector companies. The auditability and traceability of AI systems should be promoted to this end. In addition, Member States should strengthen their institutional capacities to deliver on this commitment and should collaborate with researchers and other stakeholders to investigate, prevent and mitigate any potentially malicious uses of AI systems. 56. Member States are encouraged to develop national and regional AI strategies and to consider forms of soft governance such as a certification mechanism for AI systems and the mutual recognition of their certification, according to the sensitivity of the application domain and expected impact on human rights, the environment and ecosystems, and other ethical considerations set forth in this Recommendation. Such a mechanism might include different levels of audit of systems, data, and adherence to ethical guidelines and to procedural requirements in view of ethical aspects. At the same time, such a mechanism should not hinder innovation or disadvantage small and medium enterprises or start-ups, civil society as well as research and science organizations, as a result of an excessive administrative burden. These mechanisms should also include a regular monitoring component to ensure system robustness and continued integrity and adherence to ethical guidelines over the entire life cycle of the AI system, requiring re-certification if necessary. 57. Member States and public authorities should carry out transparent self-assessment of existing and proposed AI systems, which, in particular, should include the assessment of whether the adoption of AI is appropriate and, if so, should include further assessment to determine what the appropriate method is, as well as assessment as to whether such adoption would result in violations or abuses of Member States' human rights law obligations, and if that is the case, prohibit its use. 58. Member States should encourage public entities, private sector companies and civil society organizations to involve different stakeholders in their AI governance and to consider adding the role of an independent AI Ethics Officer or some other mechanism to oversee ethical impact assessment, auditing and continuous monitoring efforts and ensure ethical guidance of AI systems. Member States, private sector companies and civil society organizations, with the support of UNESCO, are encouraged to create a network of independent AI Ethics Officers to give support to this process at national, regional and international levels. 59. Member States should foster the development of, and access to, a digital ecosystem for ethical and inclusive development of AI systems at the national level, including to address gaps in access to the AI system life cycle, while contributing to international collaboration. Such an ecosystem includes, in particular, digital technologies and infrastructure, and mechanisms for sharing AI knowledge, as appropriate. 60. Member States should establish mechanisms, in collaboration with international organizations, transnational corporations, academic institutions and civil society, to ensure the active participation of all Member States, especially LMICs, in particular LDCs, LLDCs and SIDS, in international discussions concerning AI governance. This can be through the provision of funds, ensuring equal regional participation, or any other mechanisms. Furthermore, in order to ensure the inclusiveness of AI fora, Member States should facilitate the travel of AI actors in and out of their territory, especially from LMICs, in particular LDCs, LLDCs and SIDS, for the purpose of participating in these fora. 61. Amendments to the existing or elaboration of new national legislation addressing AI systems must comply with Member States' human rights law obligations and promote human rights and fundamental freedoms throughout the AI system life cycle. Promotion thereof should also take the form of governance initiatives, good exemplars of collaborative practices regarding AI systems, and national and international technical and methodological guidelines as AI technologies advance. Diverse sectors, including the private sector, in their practices regarding AI systems must respect, protect and promote human rights and fundamental freedoms using existing and new instruments in combination with this Recommendation. 62. Member States that acquire Al systems for human rights-sensitive use cases, such as law enforcement, welfare, employment, media and information providers, health care and the independent judiciary system should provide mechanisms to monitor the social and economic impact of such systems by appropriate oversight authorities, including independent data protection authorities, sectoral oversight and public bodies responsible for oversight. 63. Member States should enhance the capacity of the judiciary to make decisions related to AI systems as per the rule of law and in line with international law and standards, including in the use of AI systems in their deliberations, while ensuring that the principle of human oversight is upheld. In case AI systems are used by the judiciary, sufficient safeguards are needed to guarantee inter alia the protection of fundamental human rights, the rule of law, judicial independence as well as the principle of human oversight, and to ensure a trustworthy, public interest-oriented and human-centric development and use of AI systems in the judiciary. 64. Member States should ensure that governments and multilateral organizations play a leading role in ensuring the safety and security of AI systems, with multi-stakeholder participation. Specifically, Member States, international organizations and other relevant bodies should develop international standards that describe measurable, testable levels of safety and transparency, so that systems can be objectively assessed and levels of compliance determined. Furthermore, Member States and business enterprises should continuously support strategic research on potential safety and security risks of AI technologies and should encourage research into transparency and explainability, inclusion and literacy by putting additional funding into those areas for different domains and at different levels, such as technical and natural language. 65. Member States should implement policies to ensure that the actions of AI actors are consistent with international human rights law, standards and principles throughout the life cycle of AI systems, while taking into full consideration the current cultural and social diversities, including local customs and religious traditions, with due regard to the precedence and universality of human rights. 66. Member States should put in place mechanisms to require AI actors to disclose and combat any kind of stereotyping in the outcomes of AI systems and data, whether by design or by negligence, and to ensure that training data sets for AI systems do not foster cultural, economic or social inequalities, prejudice, the spreading of disinformation and misinformation, and disruption of freedom of expression and access to information. Particular attention should be given to regions where the data are scarce. 67. Member States should implement policies to promote and increase diversity and inclusiveness that reflect their populations in AI development teams and training datasets, and to ensure equal access to AI technologies and their benefits, particularly for marginalized groups, both from rural and urban zones. 68. Member States should develop, review and adapt, as appropriate, regulatory frameworks to achieve accountability and responsibility for the content and outcomes of AI systems at the different phases of their life cycle. Member States should, where necessary, introduce liability frameworks or clarify the interpretation of existing frameworks to ensure the attribution of accountability for the outcomes and the functioning of AI systems. Furthermore, when developing regulatory frameworks, Member States should, in particular, take into account that ultimate responsibility and accountability must always lie with natural or legal persons and that AI systems should not be given legal personality themselves. To ensure this, such regulatory frameworks should be consistent with the principle of human oversight and establish a comprehensive approach focused on AI actors and the technological processes involved across the different stages of the AI system life cycle. 69. In order to establish norms where these do not exist, or to adapt the existing legal frameworks, Member States should involve all AI actors (including, but not limited to, researchers, representatives of civil society and law enforcement, insurers, investors, manufacturers, engineers, lawyers and users). The norms can mature into best practices, laws and regulations. Member States are further encouraged to use mechanisms such as policy prototypes and regulatory sandboxes to accelerate the development of laws, regulations and policies, including regular reviews thereof, in line with the rapid development of new technologies and ensure that laws and regulations can be tested in a safe environment before being officially adopted. Member States should support local governments in the development of local policies, regulations and laws in line with national and international legal frameworks. 70. Member States should set clear requirements for AI system transparency and explainability so as to help ensure the trustworthiness of the full AI system life cycle. Such requirements should involve the design and implementation of impact mechanisms that take into consideration the nature of application domain, intended use, target audience and feasibility of each particular AI system. POLICY AREA 3: DATA POLICY 71. Member States should work to develop data governance strategies that ensure the continual evaluation of the quality of training data for AI systems including the adequacy of the data collection and selection processes, proper data security and protection measures, as well as feedback mechanisms to learn from mistakes and share best practices among all AI actors. 72. Member States should put in place appropriate safeguards to protect the right to privacy in accordance with international law, including addressing concerns such as surveillance. Member States should, among others, adopt or enforce legislative frameworks that provide appropriate protection, compliant with international law. Member States should strongly encourage all AI actors, including business enterprises, to follow existing international standards and, in particular, to carry out adequate privacy impact assessments, as part of ethical impact assessments, which take into account the wider socio-economic impact of the intended data processing, and to apply privacy by design in their systems. Privacy should be respected, protected and promoted throughout the life cycle of AI systems. 73. Member States should ensure that individuals retain rights over their personal data and are protected by a framework, which notably foresees: transparency; appropriate safeguards for the processing of sensitive data; an appropriate level of data protection; effective and meaningful accountability schemes and mechanisms; the full enjoyment of the data subjects' rights and the ability to access and erase their personal data in AI systems, except for certain circumstances in compliance with international law; an appropriate level of protection in full compliance with data protection legislation where data are being used for commercial purposes such as enabling micro-targeted advertising, transferred cross-border; and an effective independent oversight as part of a data governance mechanism which keeps individuals in control of their personal data and fosters the benefits of a free flow of information internationally, including access to data. 74. Member States should establish their data policies or equivalent frameworks, or reinforce existing ones, to ensure full security for personal data and sensitive data, which, if disclosed, may cause exceptional damage, injury or hardship to individuals. Examples include data relating to offences, criminal proceedings and convictions, and related security measures; biometric, genetic and health data; and personal data such as that relating to race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other characteristics. 75. Member States should promote open data. In this regard, Member States should consider reviewing their policies and regulatory frameworks, including on access to information and open government to reflect AI-specific requirements and promoting mechanisms, such as open repositories for publicly funded or publicly held data and source code and data trusts, to support the safe, fair, legal and ethical sharing of data, among others. 76. Member States should promote and facilitate the use of quality and robust datasets for training, development and use of AI systems, and exercise vigilance in overseeing their collection and use. This could, if possible and feasible, include investing in the creation of gold standard datasets, including open and trustworthy datasets, which are diverse, constructed on a valid legal basis, including consent of data subjects, when required by law. Standards for annotating datasets should be encouraged, including disaggregating data on gender and other bases, so it can easily be determined how a dataset is gathered and what properties it has. 77. Member States, as also suggested in the report of the United Nations Secretary-General's High-level Panel on Digital Cooperation, with the support of the United Nations and UNESCO, should adopt a digital commons approach to data where appropriate, increase interoperability of tools and datasets and interfaces of systems hosting data, and encourage private sector companies to share the data they collect with all stakeholders, as appropriate, for research, innovation or public benefits. They should also promote public and private efforts to create collaborative platforms to share quality data in trusted and secured data spaces. POLICY AREA 4: DEVELOPMENT AND INTERNATIONAL COOPERATION 78. Member States and transnational corporations should prioritize AI ethics by including discussions of AI-related ethical issues into relevant international, intergovernmental and multi-stakeholder fora. 79. Member States should ensure that the use of AI in areas of development such as education, science, culture, communication and information, health care, agriculture and food supply, environment, natural resource and infrastructure management, economic planning and growth, among others, adheres to the values and principles set forth in this Recommendation. 80. Member States should work through international organizations to provide platforms for international cooperation on AI for development, including by contributing expertise, funding, data, domain knowledge, infrastructure, and facilitating multi-stakeholder collaboration to tackle challenging development problems, especially for LMICs, in particular LDCs, LLDCs and SIDS. 81. Member States should work to promote international collaboration on AI research and innovation, including research and innovation centres and networks that promote greater participation and leadership of researchers from LMICs and other countries, including LDCs, LLDCs and SIDS. 82. Member States should promote AI ethics research by engaging international organizations and research institutions, as well as transnational corporations, that can be a basis for the ethical use of AI systems by public and private entities, including research into the applicability of specific ethical frameworks in specific cultures and contexts, and the possibilities to develop technologically feasible solutions in line with these frameworks. 83. Member States should encourage international cooperation and collaboration in the field of AI to bridge geo-technological lines. Technological exchanges and consultations should take place between Member States and their populations, between the public and private sectors, and between and among the most and least technologically advanced countries in full respect of international law. POLICY AREA 5: ENVIRONMENT AND ECOSYSTEMS 84. Member States and business enterprises should assess the direct and indirect environmental impact throughout the AI system life cycle, including, but not limited to, its carbon footprint, energy consumption and the environmental impact of raw material extraction for supporting the manufacturing of AI technologies, and reduce the environmental impact of AI systems and data infrastructures. Member States should ensure compliance of all AI actors with environmental law, policies and practices. 85. Member States should introduce incentives, when needed and appropriate, to ensure the development and adoption of rights-based and ethical AI-powered solutions for disaster risk resilience; the monitoring, protection and regeneration of the environment and ecosystems; and the preservation of the planet. These AI systems should involve the participation of local and indigenous communities throughout the life cycle of AI systems and should support circular economy type approaches and sustainable consumption and production patterns. Some examples include using AI systems, when needed and appropriate, to: (a) Support the protection, monitoring and management of natural resources. (b) Support the prediction, prevention, control and mitigation of climate-related problems. (c) Support a more efficient and sustainable food ecosystem. (d) Support the acceleration of access to and mass adoption of sustainable energy. (e) Enable and promote the mainstreaming of sustainable infrastructure, sustainable business models and sustainable finance for sustainable development. (f) Detect pollutants or predict levels of pollution and thus help relevant stakeholders identify, plan and put in place targeted interventions to prevent and reduce pollution and exposure. 86. When choosing AI methods, given the potential data-intensive or resource-intensive character of some of them and the respective impact on the environment, Member States should ensure that AI actors, in line with the principle of proportionality, favour data, energy and resource-efficient AI methods. Requirements should be developed to ensure that appropriate evidence is available to show that an AI application will have the intended effect, or that safeguards accompanying an AI application can support the justification for its use. If this cannot be done, the precautionary principle must be favoured, and in instances where there are disproportionate negative impacts on the environment, AI should not be used. POLICY AREA 6: GENDER 87. Member States should ensure that the potential for digital technologies and artificial intelligence to contribute to achieving gender equality is fully maximized, and must ensure that the human rights and fundamental freedoms of girls and women, and their safety and integrity are not violated at any stage of the AI system life cycle. Moreover, Ethical Impact Assessment should include a transversal gender perspective. 88. Member States should have dedicated funds from their public budgets linked to financing gender-responsive schemes, ensure that national digital policies include a gender action plan, and develop relevant policies, for example, on labour education, targeted at supporting girls and women to make sure they are not left out of the digital economy powered by AI. Special investment in providing targeted programmes and gender-specific language, to increase the opportunities of girls' and women's participation in science, technology, engineering, and mathematics (STEM), including information and communication technologies (ICT) disciplines, preparedness, employability, equal career development and professional growth of girls and women, should be considered and implemented. 89. Member States should ensure that the potential of AI systems to advance the achievement of gender equality is realized. They should ensure that these technologies do not exacerbate the already wide gender gaps existing in several fields in the analogue world, and instead eliminate those gaps. These gaps include: the gender wage gap; the unequal representation in certain professions and activities; the lack of representation at top management positions, boards of directors, or research teams in the AI field; the education gap; the digital and AI access, adoption, usage and affordability gap; and the unequal distribution of unpaid work and of the caring responsibilities in our societies. 90. Member States should ensure that gender stereotyping and discriminatory biases are not translated into AI systems, and instead identify and proactively redress these. Efforts are necessary to avoid the compounding negative effect of technological divides in achieving gender equality and avoiding violence such as harassment, bullying or trafficking of girls and women and under-represented groups, including in the online domain. 91. Member States should encourage female entrepreneurship, participation and engagement in all stages of an AI system life cycle by offering and promoting economic, regulatory incentives, among other incentives and support schemes, as well as policies that aim at a balanced gender participation in AI research in academia, gender representation on digital and AI companies' top management positions, boards of directors and research teams. Member States should ensure that public funds (for innovation, research and technologies) are channelled to inclusive programmes and companies, with clear gender representation, and that private funds are similarly encouraged through affirmative action principles. Policies on harassment-free environments should be developed and enforced, together with the encouragement of the transfer of best practices on how to promote diversity throughout the AI system life cycle. 92. Member States should promote gender diversity in AI research in academia and industry by offering incentives to girls and women to enter the field, putting in place mechanisms to fight gender stereotyping and harassment within the AI research community, and encouraging academic and private entities to share best practices on how to enhance gender diversity. 93. UNESCO can help form a repository of best practices for incentivizing the participation of girls, women and under-represented groups in all stages of the AI system life cycle. POLICY AREA 7: CULTURE 94. Member States are encouraged to incorporate AI systems, where appropriate, in the preservation, enrichment, understanding, promotion, management and accessibility of tangible, documentary and intangible cultural heritage, including endangered languages as well as indigenous languages and knowledges, for example by introducing or updating educational programmes related to the application of AI systems in these areas, where appropriate, and by ensuring a participatory approach, targeted at institutions and the public. 95. Member States are encouraged to examine and address the cultural impact of AI systems, especially natural language processing (NLP) applications such as automated translation and voice assistants, on the nuances of human language and expression. Such assessments should provide input for the design and implementation of strategies that maximize the benefits from these systems by bridging cultural gaps and increasing human understanding, as well as addressing the negative implications such as the reduction of use, which could lead to the disappearance of endangered languages, local dialects, and tonal and cultural variations associated with human language and expression. 96. Member States should promote AI education and digital training for artists and creative professionals to assess the suitability of AI technologies for use in their profession, and contribute to the design and implementation of suitable AI technologies, as AI technologies are being used to create, produce, distribute, broadcast and consume a variety of cultural goods and services, bearing in mind the importance of preserving cultural heritage, diversity and artistic freedom. 97. Member States should promote awareness and evaluation of AI tools among local cultural industries and small and medium enterprises working in the field of culture, to avoid the risk of concentration in the cultural market. 98. Member States should engage technology companies and other stakeholders to promote a diverse supply of and plural access to cultural expressions, and in particular to ensure that algorithmic recommendation enhances the visibility and discoverability of local content. 99. Member States should foster new research at the intersection between AI and intellectual property (IP), for example to determine whether or how to protect with IP rights the works created by means of Al technologies. Member States should also assess how AI technologies are affecting the rights or interests of IP owners, whose works are used to research, develop, train or implement AI applications. 100. Member States should encourage museums, galleries, libraries and archives at the national level to use AI systems to highlight their collections and enhance their libraries, databases and knowledge base, while also providing access to their users. POLICY AREA 8: EDUCATION AND RESEARCH 101. Member States should work with international organizations, educational institutions and private and non-governmental entities to provide adequate AI literacy education to the public on all levels in all countries in order to empower people and reduce the digital divides and digital access inequalities resulting from the wide adoption of AI systems. 102. Member States should promote the acquisition of 'prerequisite skills' for AI education, such as basic literacy, numeracy, coding and digital skills, and media and information literacy, as well as critical and creative thinking, teamwork, communication, socio-emotional and AI ethics skills, especially in countries and in regions or areas within countries where there are notable gaps in the education of these skills. 103. Member States should promote general awareness programmes about AI developments, including on data and the opportunities and challenges brought about by AI technologies, the impact of AI systems on human rights and their implications, including children's rights. These programmes should be accessible to non-technical as well as technical groups. 104. Member States should encourage research initiatives on the responsible and ethical use of AI technologies in teaching, teacher training and e-learning, among other issues, to enhance opportunities and mitigate the challenges and risks involved in this area. The initiatives should be accompanied by an adequate assessment of the quality of education and impact on students and teachers of the use of AI technologies. Member States should also ensure that AI technologies empower students and teachers and enhance their experience, bearing in mind that relational and social aspects and the value of traditional forms of education are vital in teacher-student and student-student relationships and should be considered when discussing the adoption of AI technologies in education. AI systems used in learning should be subject to strict requirements when it comes to the monitoring, assessment of abilities, or prediction of the learners' behaviours. AI should support the learning process without reducing cognitive abilities and without extracting sensitive information, in compliance with relevant personal data protection standards. The data handed over to acquire knowledge collected during the learner's interactions with the AI system must not be subject to misuse, misappropriation or criminal exploitation, including for commercial purposes. 105. Member States should promote the participation and leadership of girls and women, diverse ethnicities and cultures, persons with disabilities, marginalized and vulnerable people or people in vulnerable situations, minorities and all persons not enjoying the full benefits of digital inclusion, in AI education programmes at all levels, as well as the monitoring and sharing of best practices in this regard with other Member States. 106. Member States should develop, in accordance with their national education programmes and traditions, AI ethics curricula for all levels, and promote cross-collaboration between AI technical skills education and humanistic, ethical and social aspects of AI education. Online courses and digital resources of AI ethics education should be developed in local languages, including indigenous languages, and take into account the diversity of environments, especially ensuring accessibility of formats for persons with disabilities. 107. Member States should promote and support AI research, notably AI ethics research, including for example through investing in such research or by creating incentives for the public and private sectors to invest in this area, recognizing that research contributes significantly to the further development and improvement of AI technologies with a view to promoting international law and the values and principles set forth in this Recommendation. Member States should also publicly promote the best practices of, and cooperation with, researchers and companies who develop AI in an ethical manner. 108. Member States should ensure that AI researchers are trained in research ethics and require them to include ethical considerations in their designs, products and publications, especially in the analyses of the datasets they use, how they are annotated, and the quality and scope of the results with possible applications. Member States should encourage private sector companies to facilitate the access of the scientific community to their data for research, especially in LMICs, in particular LDCs, LLDCs and SIDS. This access should conform to relevant privacy and data protection standards. 110. To ensure a critical evaluation of AI research and proper monitoring of potential misuses or adverse effects, Member States should ensure that any future developments with regards to AI technologies should be based on rigorous and independent scientific research, and promote interdisciplinary AI research by including disciplines other than science, technology, engineering and mathematics (STEM), such as cultural studies, education, ethics, international relations, law, linguistics, philosophy, political science, sociology and psychology. 111. Recognizing that AI technologies present great opportunities to help advance scientific knowledge and practice, especially in traditionally model-driven disciplines, Member States should encourage scientific communities to be aware of the benefits, limits and risks of their use; this includes attempting to ensure that conclusions drawn from data-driven approaches, models and treatments are robust and sound. Furthermore, Member States should welcome and support the role of the scientific community in contributing to policy and in cultivating awareness of the strengths and weaknesses of AI technologies. POLICY AREA 9: COMMUNICATION AND INFORMATION 112. Member States should use AI systems to improve access to information and knowledge. This can include support to researchers, academia, journalists, the general public and developers, to enhance freedom of expression, academic and scientific freedoms, access to information, and increased proactive disclosure of official data and information. 113. Member States should ensure that AI actors respect and promote freedom of expression as well as access to information with regard to automated content generation, moderation and curation. Appropriate frameworks, including regulation, should enable transparency of online communication and information operators and ensure users have access to a diversity of viewpoints, as well as processes for prompt notification to the users on the reasons for removal or other treatment of content, and appeal mechanisms that allow users to seek redress. 114. Member States should invest in and promote digital and media and information literacy skills to strengthen critical thinking and competencies needed to understand the use and implication of AI systems, in order to mitigate and counter disinformation, misinformation and hate speech. A better understanding and evaluation of both the positive and potentially harmful effects of recommender systems should be part of those efforts. 115. Member States should create enabling environments for media to have the rights and resources to effectively report on the benefits and harms of AI systems, and also encourage media to make ethical use of AI systems in their operations. POLICY AREA 10: ECONOMY AND LABOUR 116. Member States should assess and address the impact of AI systems on labour markets and its implications for education requirements, in all countries and with special emphasis on countries where the economy is labour-intensive. This can include the introduction of a wider range of 'core' and interdisciplinary skills at all education levels to provide current workers and new generations a fair chance of finding jobs in a rapidly changing market, and to ensure their awareness of the ethical aspects of AI systems. Skills such as 'learning how to learn', communication, critical thinking, teamwork, empathy, and the ability to transfer one's knowledge across domains, should be taught alongside specialist, technical skills, as well as low-skilled tasks. Being transparent about what skills are in demand and updating curricula around these are key. 117. Member States should support collaboration agreements among governments, academic institutions, vocational education and training institutions, industry, workers' organizations and civil society to bridge the gap of skillset requirements to align training programmes and strategies with the implications of the future of work and the needs of industry, including small and medium enterprises. Project-based teaching and learning approaches for AI should be promoted, allowing for partnerships between public institutions, private sector companies, universities and research centres. 118. Member States should work with private sector companies, civil society organizations and other stakeholders, including workers and unions to ensure a fair transition for at-risk employees. This includes putting in place upskilling and reskilling programmes, finding effective mechanisms of retaining employees during those transition periods, and exploring 'safety net' programmes for those who cannot be retrained. Member States should develop and implement programmes to research and address the challenges identified that could include upskilling and reskilling, enhanced social protection, proactive industry policies and interventions, tax benefits, new taxation forms, among others. Member States should ensure that there is sufficient public funding to support these programmes. Relevant regulations, such as tax regimes, should be carefully examined and changed if needed to counteract the consequences of unemployment caused by AI-based automation. 119. Member States should encourage and support researchers to analyze the impact of AI systems on the local labour environment in order to anticipate future trends and challenges. These studies should have an interdisciplinary approach and investigate the impact of AI systems on economic, social and geographic sectors, as well as on human-robot interactions and human-human relationships, in order to advise on reskilling and redeployment best practices. 120. Member States should take appropriate steps to ensure competitive markets and consumer protection, considering possible measures and mechanisms at national, regional and international levels, to prevent abuse of dominant market positions, including by monopolies, in relation to AI systems throughout their life cycle, whether these are data, research, technology, or market. Member States should prevent the resulting inequalities, assess relevant markets and promote competitive markets. Due consideration should be given to LMICs, in particular LDCs, LLDCs and SIDS, which are more exposed and vulnerable to the possibility of abuses of market dominance as a result of a lack of infrastructure, human capacity and regulations, among other factors. AI actors developing AI systems in countries which have established or adopted ethical standards on AI should respect these standards when exporting these products, developing or applying their AI systems in countries where such standards may not exist, while respecting applicable international law and domestic legislation, standards and practices of these countries. POLICY AREA 11: HEALTH AND SOCIAL WELL-BEING 121. Member States should endeavour to employ effective AI systems for improving human health and protecting the right to life, including mitigating disease outbreaks, while building and maintaining international solidarity to tackle global health risks and uncertainties, and ensure that their deployment of AI systems in health care be consistent with international law and their human rights law obligations. Member States should ensure that actors involved in health care AI systems take into consideration the importance of a patient's relationships with their family and with health care staff. 122. Member States should ensure that the development and deployment of AI systems related to health in general and mental health in particular, paying due attention to children and youth, is regulated to the effect that they are safe, effective, efficient, scientifically and medically proven and enable evidence-based innovation and medical progress. Moreover, in the related area of digital health interventions, Member States are strongly encouraged to actively involve patients and their representatives in all relevant steps of the development of the system. (a) ensuring oversight to minimize and mitigate bias; (b) ensuring that the professional, the patient, caregiver or service user is included as a 'domain expert' in the team in all relevant steps when developing the algorithms; (c) paying due attention to privacy because of the potential need for being medically monitored and ensuring that all relevant national and international data protection requirements are met; (d) ensuring effective mechanisms so that those whose personal data is being analysed are aware of and provide informed consent for the use and analysis of their data, without preventing access to health care; (e) ensuring the human care and final decision of diagnosis and treatment are taken always by humans while acknowledging that AI systems can also assist in their work; (f) ensuring, where necessary, the review of AI systems by an ethical research committee prior to clinical use. 124. Member States should establish research on the effects and regulation of potential harms to mental health related to AI systems, such as higher degrees of depression, anxiety, social isolation, developing addiction, trafficking, radicalization and misinformation, among others. 125. Member States should develop guidelines for human-robot interactions and their impact on human-human relationships, based on research and directed at the future development of robots, and with special attention to the mental and physical health of human beings. Particular attention should be given to the use of robots in health care and the care for older persons and persons with disabilities, in education, and robots for use by children, toy robots, chatbots and companion robots for children and adults. Furthermore, assistance of AI technologies should be applied to increase the safety and ergonomic use of robots, including in a human-robot working environment. Special attention should be paid to the possibility of using AI to manipulate and abuse human cognitive biases. 126. Member States should ensure that human-robot interactions comply with the same values and principles that apply to any other AI systems, including human rights and fundamental freedoms, the promotion of diversity, and the protection of vulnerable people or people in vulnerable situations. Ethical questions related to AI-powered systems for neurotechnologies and brain-computer interfaces should be considered in order to preserve human dignity and autonomy. 127. Member States should ensure that users can easily identify whether they are interacting with a living being, or with an AI system imitating human or animal characteristics, and can effectively refuse such interaction and request human intervention. 128. Member States should implement policies to raise awareness about the anthropomorphization of AI technologies and technologies that recognize and mimic human emotions, including in the language used to mention them, and assess the manifestations, ethical implications and possible limitations of such anthropomorphization, in particular in the context of robot-human interaction and especially when children are involved. 129. Member States should encourage and promote collaborative research into the effects of long-term interaction of people with AI systems, paying particular attention to the psychological and cognitive impact that these systems can have on children and young people. This should be done using multiple norms, principles, protocols, disciplinary approaches, and assessment of the modification of behaviours and habits, as well as careful evaluation of the downstream cultural and societal impacts. Furthermore, Member States should encourage research on the effect of AI technologies on health system performance and health outcomes. 130. Member States, as well as all stakeholders, should put in place mechanisms to meaningfully engage children and young people in conversations, debates and decision-making with regard to the impact of AI systems on their lives and futures.",
  "embedding": [
    0.16796875,
    -0.154296875,
    0.1494140625,
    0.00885009765625,
    0.033203125,
    -0.10498046875,
    -0.012939453125,
    0.01385498046875,
    0.0255126953125,
    0.0184326171875,
    0.031494140625,
    0.126953125,
    0.0390625,
    -0.0615234375,
    0.10693359375,
    -0.06103515625,
    -0.07470703125,
    0.005279541015625,
    -0.036376953125,
    -0.123046875,
    0.045166015625,
    -0.08984375,
    0.06494140625,
    0.11962890625,
    -0.10302734375,
    0.06591796875,
    -0.03515625,
    0.03662109375,
    0.0015106201171875,
    0.005462646484375,
    0.039794921875,
    -0.1083984375,
    0.0186767578125,
    -0.076171875,
    -0.0006103515625,
    0.044921875,
    0.0693359375,
    -0.017822265625,
    -0.02197265625,
    -0.040771484375,
    -0.017822265625,
    -0.02880859375,
    0.05810546875,
    -0.08740234375,
    0.06689453125,
    0.10498046875,
    0.072265625,
    -0.008544921875,
    -0.0693359375,
    -0.0380859375,
    0.07861328125,
    0.07470703125,
    -0.08349609375,
    0.058349609375,
    0.004364013671875,
    0.0198974609375,
    0.037353515625,
    0.005157470703125,
    -0.06494140625,
    -0.01422119140625,
    -0.06689453125,
    0.0615234375,
    -0.01385498046875,
    -0.0211181640625,
    -0.036865234375,
    0.0771484375,
    -0.028564453125,
    -0.033203125,
    -0.02197265625,
    -0.035400390625,
    -0.0208740234375,
    -0.00173187255859375,
    -0.04833984375,
    -0.0062255859375,
    0.004730224609375,
    0.016357421875,
    -0.0272216796875,
    0.055419921875,
    -0.00173187255859375,
    0.0291748046875,
    0.0693359375,
    0.052001953125,
    0.040771484375,
    0.021240234375,
    0.038330078125,
    0.059814453125,
    -0.08935546875,
    -0.007415771484375,
    0.00110626220703125,
    -0.004425048828125,
    0.037109375,
    -0.04541015625,
    -0.052734375,
    -0.0673828125,
    0.0791015625,
    0.0159912109375,
    -0.021728515625,
    0.0033721923828125,
    -0.03955078125,
    0.000045299530029296875,
    -0.055908203125,
    0.042724609375,
    -0.07861328125,
    0.01116943359375,
    -0.026611328125,
    0.058349609375,
    0.00156402587890625,
    -0.0208740234375,
    -0.0888671875,
    -0.05810546875,
    -0.005340576171875,
    -0.0093994140625,
    -0.021484375,
    0.031494140625,
    0.0294189453125,
    0.04443359375,
    -0.03076171875,
    0.05029296875,
    0.05224609375,
    -0.035400390625,
    0.02294921875,
    -0.01361083984375,
    0.000858306884765625,
    0.023681640625,
    0.0242919921875,
    -0.025634765625,
    -0.0228271484375,
    0.052978515625,
    -0.006866455078125,
    -0.057373046875,
    0.01092529296875,
    0.04052734375,
    -0.0498046875,
    -0.01708984375,
    -0.009033203125,
    0.0255126953125,
    -0.00799560546875,
    -0.034912109375,
    -0.0111083984375,
    0.0274658203125,
    0.007476806640625,
    0.005706787109375,
    -0.03125,
    0.012939453125,
    -0.0033721923828125,
    -0.0291748046875,
    -0.01507568359375,
    -0.021728515625,
    -0.0157470703125,
    0.054443359375,
    0.03271484375,
    0.0216064453125,
    -0.01171875,
    -0.024169921875,
    0.048828125,
    0.01507568359375,
    0.035888671875,
    0.00579833984375,
    0.00153350830078125,
    -0.004913330078125,
    -0.0244140625,
    0.036376953125,
    -0.023681640625,
    -0.0498046875,
    -0.0439453125,
    0.0184326171875,
    -0.017822265625,
    0.0262451171875,
    -0.0155029296875,
    -0.000885009765625,
    -0.0294189453125,
    0.0380859375,
    0.0255126953125,
    -0.0206298828125,
    -0.034912109375,
    0.007537841796875,
    0.02490234375,
    0.09033203125,
    0.031494140625,
    0.058837890625,
    0.03076171875,
    -0.0252685546875,
    -0.032958984375,
    0.046142578125,
    -0.080078125,
    -0.000812530517578125,
    0.0123291015625,
    0.0037689208984375,
    0.008544921875,
    -0.00775146484375,
    -0.00921630859375,
    -0.00958251953125,
    0.05517578125,
    0.03857421875,
    -0.0301513671875,
    0.0244140625,
    -0.048583984375,
    0.005584716796875,
    -0.00848388671875,
    -0.0277099609375,
    0.0035858154296875,
    -0.0048828125,
    0.00579833984375,
    0.045654296875,
    -0.0203857421875,
    -0.0052490234375,
    -0.003021240234375,
    0.00799560546875,
    -0.02392578125,
    0.0238037109375,
    -0.01495361328125,
    0.024169921875,
    0.006072998046875,
    -0.0072021484375,
    -0.0634765625,
    -0.01025390625,
    0.06103515625,
    0.047119140625,
    0.0128173828125,
    0.015625,
    0.006622314453125,
    0.00048065185546875,
    0.006988525390625,
    -0.01904296875,
    -0.01123046875,
    -0.003631591796875,
    0.002655029296875,
    0.01953125,
    -0.018798828125,
    0.0233154296875,
    0.01190185546875,
    0.0078125,
    -0.0322265625,
    0.04052734375,
    0.04541015625,
    -0.02099609375,
    -0.00049591064453125,
    0.05712890625,
    0.0732421875,
    0.0024261474609375,
    -0.053955078125,
    -0.01458740234375,
    -0.01611328125,
    -0.0023956298828125,
    -0.0390625,
    -0.025634765625,
    -0.025390625,
    -0.037109375,
    -0.05712890625,
    -0.00457763671875,
    0.0123291015625,
    -0.00848388671875,
    -0.0291748046875,
    -0.01708984375,
    0.0169677734375,
    -0.0279541015625,
    -0.00506591796875,
    -0.0025482177734375,
    -0.0291748046875,
    0.01611328125,
    -0.02392578125,
    -0.0081787109375,
    -0.0206298828125,
    0.003143310546875,
    0.011962890625,
    -0.0211181640625,
    -0.01519775390625,
    -0.006561279296875,
    -0.0108642578125,
    -0.035888671875,
    0.0034332275390625,
    -0.0024261474609375,
    0.0064697265625,
    0.05078125,
    0.01409912109375,
    0.025146484375,
    -0.0203857421875,
    0.0245361328125,
    0.03076171875,
    -0.0294189453125,
    -0.058349609375,
    0.0003910064697265625,
    0.0242919921875,
    0.01092529296875,
    -0.016845703125,
    -0.0186767578125,
    -0.00799560546875,
    0.0296630859375,
    0.00183868408203125,
    -0.0120849609375,
    0.0025177001953125,
    -0.01458740234375,
    0.001800537109375,
    0.033935546875,
    0.017578125,
    0.0162353515625,
    -0.08203125,
    0.0045166015625,
    0.050537109375,
    0.016357421875,
    -0.0277099609375,
    0.0169677734375,
    0.044677734375,
    0.0478515625,
    -0.00213623046875,
    -0.000667572021484375,
    0.00011157989501953125,
    -0.045654296875,
    -0.0191650390625,
    0.003509521484375,
    -0.01104736328125,
    -0.020263671875,
    0.01336669921875,
    0.018310546875,
    -0.03515625,
    0.004241943359375,
    -0.03125,
    0.0120849609375,
    -0.0113525390625,
    -0.00604248046875,
    -0.00787353515625,
    0.01287841796875,
    -0.033447265625,
    0.03759765625,
    -0.044921875,
    -0.028076171875,
    0.011962890625,
    -0.0189208984375,
    0.0166015625,
    0.001678466796875,
    -0.0091552734375,
    -0.029052734375,
    0.0181884765625,
    0.06884765625,
    0.003814697265625,
    -0.03173828125,
    -0.0203857421875,
    0.005218505859375,
    0.00946044921875,
    -0.015869140625,
    0.022216796875,
    -0.002777099609375,
    0.06396484375,
    -0.01806640625,
    0.002349853515625,
    0.038330078125,
    0.0108642578125,
    -0.036865234375,
    0.0252685546875,
    0.052490234375,
    -0.0191650390625,
    0.005645751953125,
    -0.01470947265625,
    -0.000507354736328125,
    0.005157470703125,
    0.033935546875,
    -0.006591796875,
    -0.018798828125,
    -0.01287841796875,
    -0.0654296875,
    -0.0181884765625,
    0.0233154296875,
    0.0128173828125,
    0.0625,
    -0.006134033203125,
    -0.015625,
    0.0654296875,
    -0.002532958984375,
    0.012451171875,
    0.00628662109375,
    -0.029052734375,
    -0.05126953125,
    -0.017333984375,
    -0.007354736328125,
    -0.0118408203125,
    0.00107574462890625,
    -0.001312255859375,
    0.005706787109375,
    0.0498046875,
    -0.0155029296875,
    0.01409912109375,
    -0.04736328125,
    -0.005889892578125,
    -0.005218505859375,
    0.004669189453125,
    -0.01031494140625,
    0.0546875,
    -0.041748046875,
    0.0244140625,
    -0.01611328125,
    -0.004241943359375,
    -0.04541015625,
    0.0228271484375,
    -0.021240234375,
    -0.053955078125,
    0.004425048828125,
    0.03662109375,
    -0.0732421875,
    -0.0120849609375,
    0.055908203125,
    0.049560546875,
    0.0220947265625,
    0.01177978515625,
    -0.03662109375,
    0.042724609375,
    0.0244140625,
    -0.00872802734375,
    -0.00982666015625,
    -0.056396484375,
    0.00811767578125,
    -0.037353515625,
    0.052490234375,
    -0.016357421875,
    0.038818359375,
    0.01025390625,
    -0.058349609375,
    0.03125,
    0.0108642578125,
    -0.0206298828125,
    -0.01397705078125,
    0.00311279296875,
    0.0098876953125,
    -0.01409912109375,
    -0.01385498046875,
    0.038818359375,
    -0.00164794921875,
    -0.016845703125,
    -0.0269775390625,
    0.047119140625,
    -0.01177978515625,
    -0.0277099609375,
    0.004425048828125,
    0.038330078125,
    0.0272216796875,
    0.00897216796875,
    -0.0262451171875,
    0.01611328125,
    -0.0189208984375,
    -0.01312255859375,
    -0.0177001953125,
    0.0191650390625,
    0.048828125,
    -0.00982666015625,
    -0.01422119140625,
    0.01275634765625,
    0.01904296875,
    0.042236328125,
    -0.068359375,
    -0.0281982421875,
    -0.0125732421875,
    -0.0223388671875,
    0.0189208984375,
    -0.038818359375,
    -0.01226806640625,
    0.005157470703125,
    0.030517578125,
    0.052490234375,
    -0.007415771484375,
    0.0296630859375,
    0.0103759765625,
    0.0118408203125,
    -0.053955078125,
    0.036865234375,
    -0.004302978515625,
    0.08349609375,
    0.003082275390625,
    0.0625,
    -0.00183868408203125,
    -0.00188446044921875,
    -0.0303955078125,
    0.000476837158203125,
    0.01519775390625,
    -0.004638671875,
    -0.03271484375,
    -0.01043701171875,
    -0.0111083984375,
    0.0072021484375,
    -0.021484375,
    -0.006805419921875,
    0.03173828125,
    0.013916015625,
    -0.043212890625,
    0.03125,
    0.0291748046875,
    0.02490234375,
    -0.0130615234375,
    -0.034912109375,
    -0.00518798828125,
    0.0286865234375,
    0.0272216796875,
    0.0108642578125,
    -0.0028533935546875,
    0.006561279296875,
    0.07568359375,
    0.01904296875,
    -0.01806640625,
    0.04345703125,
    -0.0181884765625,
    -0.0191650390625,
    -0.0732421875,
    -0.06787109375,
    -0.0103759765625,
    0.01708984375,
    0.021484375,
    -0.0203857421875,
    -0.0135498046875,
    -0.008544921875,
    0.001617431640625,
    -0.00113677978515625,
    0.007598876953125,
    -0.0185546875,
    0.01708984375,
    -0.0107421875,
    0.005523681640625,
    0.0390625,
    0.0303955078125,
    0.004730224609375,
    0.0091552734375,
    -0.0157470703125,
    0.006622314453125,
    -0.0179443359375,
    0.0057373046875,
    0.05029296875,
    -0.050048828125,
    0.03125,
    0.02001953125,
    -0.00013065338134765625,
    -0.021728515625,
    -0.0001888275146484375,
    0.00634765625,
    0.0341796875,
    0.00823974609375,
    0.01507568359375,
    -0.01312255859375,
    -0.0299072265625,
    0.022216796875,
    -0.002105712890625,
    -0.0277099609375,
    -0.01348876953125,
    0.0091552734375,
    -0.01275634765625,
    -0.023193359375,
    -0.00982666015625,
    -0.058349609375,
    -0.060791015625,
    0.00173187255859375,
    -0.00836181640625,
    0.037353515625,
    0.02099609375,
    0.00787353515625,
    -0.016357421875,
    -0.006103515625,
    0.0059814453125,
    0.016357421875,
    0.0003204345703125,
    -0.0703125,
    -0.007415771484375,
    -0.006927490234375,
    -0.001922607421875,
    -0.0037994384765625,
    0.0191650390625,
    -0.002410888671875,
    0.00653076171875,
    -0.01409912109375,
    -0.025634765625,
    0.01031494140625,
    0.01171875,
    0.0167236328125,
    -0.00982666015625,
    0.015869140625,
    -0.028564453125,
    0.001312255859375,
    -0.033203125,
    0.0294189453125,
    0.029052734375,
    -0.0301513671875,
    0.03173828125,
    0.025634765625,
    0.0120849609375,
    0.016357421875,
    -0.033447265625,
    -0.006988525390625,
    -0.005859375,
    0.038818359375,
    0.031005859375,
    0.036376953125,
    -0.0260009765625,
    -0.027587890625,
    0.0031890869140625,
    -0.019287109375,
    0.034912109375,
    -0.005218505859375,
    0.0152587890625,
    0.003509521484375,
    0.01422119140625,
    0.01318359375,
    -0.0179443359375,
    -0.04150390625,
    -0.0076904296875,
    0.0137939453125,
    -0.0673828125,
    -0.0062255859375,
    0.0142822265625,
    -0.00506591796875,
    0.00872802734375,
    0.037353515625,
    0.00640869140625,
    0.003204345703125,
    -0.044677734375,
    -0.0019683837890625,
    -0.00555419921875,
    0.0286865234375,
    -0.038330078125,
    -0.046142578125,
    0.033447265625,
    0.0498046875,
    0.004547119140625,
    -0.04052734375,
    -0.006561279296875,
    0.0211181640625,
    0.02197265625,
    -0.034423828125,
    0.016845703125,
    0.00011491775512695312,
    0.006439208984375,
    -0.0294189453125,
    0.04443359375,
    0.044921875,
    -0.011474609375,
    0.0107421875,
    0.0013275146484375,
    0.03564453125,
    0.046875,
    0.008544921875,
    0.0208740234375,
    0.0257568359375,
    0.0032196044921875,
    -0.01416015625,
    0.0086669921875,
    0.041259765625,
    0.035400390625,
    -0.013671875,
    -0.0194091796875,
    0.034912109375,
    -0.00946044921875,
    -0.046875,
    0.026123046875,
    -0.01385498046875,
    0.00946044921875,
    -0.02783203125,
    -0.0126953125,
    0.038330078125,
    -0.0042724609375,
    -0.00836181640625,
    -0.046875,
    -0.01165771484375,
    -0.05029296875,
    0.0198974609375,
    -0.02392578125,
    -0.03515625,
    0.00616455078125,
    0.0017547607421875,
    0.054443359375,
    -0.0301513671875,
    -0.00323486328125,
    -0.01116943359375,
    0.01483154296875,
    0.01226806640625,
    -0.00830078125,
    0.00140380859375,
    0.006195068359375,
    -0.015625,
    0.0196533203125,
    -0.016845703125,
    0.01171875,
    0.01202392578125,
    0.020263671875,
    -0.004638671875,
    -0.0106201171875,
    -0.01422119140625,
    -0.01055908203125,
    -0.007415771484375,
    -0.0203857421875,
    0.03125,
    0.00020503997802734375,
    -0.001495361328125,
    0.005706787109375,
    -0.01458740234375,
    0.01177978515625,
    0.0089111328125,
    -0.017333984375,
    -0.00145721435546875,
    0.0211181640625,
    -0.043212890625,
    0.0439453125,
    -0.00982666015625,
    0.009033203125,
    0.02099609375,
    0.0264892578125,
    0.012451171875,
    -0.0390625,
    -0.040283203125,
    0.029052734375,
    0.00665283203125,
    -0.0301513671875,
    0.026611328125,
    0.0225830078125,
    0.005645751953125,
    0.0130615234375,
    0.006317138671875,
    -0.0225830078125,
    0.0213623046875,
    0.00177764892578125,
    -0.0262451171875,
    -0.00628662109375,
    -0.0281982421875,
    0.03369140625,
    0.0069580078125,
    0.01495361328125,
    -0.052490234375,
    0.039306640625,
    0.017333984375,
    -0.00445556640625,
    -0.0380859375,
    -0.01708984375,
    0.01019287109375,
    0.0247802734375,
    0.03271484375,
    -0.015869140625,
    -0.03125,
    -0.036865234375,
    -0.00567626953125,
    -0.00136566162109375,
    0.004913330078125,
    -0.0103759765625,
    -0.00885009765625,
    0.0390625,
    0.02001953125,
    0.01043701171875,
    -0.042236328125,
    0.0024566650390625,
    0.03759765625,
    -0.015625,
    0.0546875,
    -0.0059814453125,
    -0.05126953125,
    0.000370025634765625,
    0.0233154296875,
    -0.00958251953125,
    -0.007354736328125,
    0.004425048828125,
    0.0272216796875,
    -0.00188446044921875,
    -0.03466796875,
    0.0022735595703125,
    0.01116943359375,
    -0.038330078125,
    -0.0113525390625,
    0.01141357421875,
    -0.053466796875,
    -0.03955078125,
    0.03466796875,
    -0.005279541015625,
    0.01068115234375,
    0.006683349609375,
    0.03076171875,
    -0.02001953125,
    -0.0260009765625,
    -0.0194091796875,
    -0.0291748046875,
    -0.002655029296875,
    -0.01904296875,
    0.0145263671875,
    -0.00115966796875,
    -0.00494384765625,
    0.0157470703125,
    -0.01495361328125,
    0.0185546875,
    -0.016357421875,
    -0.0185546875,
    -0.0050048828125,
    0.020263671875,
    -0.02734375,
    0.0206298828125,
    0.017822265625,
    0.033203125,
    -0.013427734375,
    -0.01806640625,
    -0.0181884765625,
    -0.00909423828125,
    -0.046875,
    -0.01507568359375,
    -0.026123046875,
    0.00067901611328125,
    -0.0031280517578125,
    -0.006561279296875,
    -0.0303955078125,
    0.004669189453125,
    0.01507568359375,
    0.017578125,
    0.0244140625,
    -0.00762939453125,
    0.007354736328125,
    -0.0123291015625,
    0.00555419921875,
    0.0225830078125,
    0.01171875,
    -0.005279541015625,
    0.0084228515625,
    -0.024169921875,
    0.0186767578125,
    0.0123291015625,
    0.015869140625,
    -0.022705078125,
    -0.00360107421875,
    -0.01385498046875,
    -0.0026702880859375,
    -0.01171875,
    -0.0159912109375,
    0.060791015625,
    -0.01385498046875,
    0.02197265625,
    -0.007293701171875,
    -0.0057373046875,
    -0.0263671875,
    0.0015106201171875,
    -0.0010223388671875,
    -0.0015716552734375,
    0.0036468505859375,
    0.03271484375,
    -0.005645751953125,
    0.01470947265625,
    -0.043701171875,
    0.036376953125,
    -0.0028533935546875,
    -0.0030059814453125,
    -0.0245361328125,
    0.00927734375,
    -0.01806640625,
    0.007415771484375,
    -0.031494140625,
    -0.01519775390625,
    -0.00726318359375,
    -0.001800537109375,
    -0.01300048828125,
    0.03369140625,
    -0.02490234375,
    0.006927490234375,
    0.0208740234375,
    -0.025390625,
    -0.00982666015625,
    -0.015380859375,
    0.0054931640625,
    -0.00408935546875,
    -0.044189453125,
    0.00016117095947265625,
    0.0037078857421875,
    0.0206298828125,
    0.000518798828125,
    -0.01239013671875,
    -0.01953125,
    -0.009765625,
    -0.0322265625,
    -0.03466796875,
    -0.019775390625,
    0.042236328125,
    -0.04052734375,
    0.0054931640625,
    0.0205078125,
    -0.004669189453125,
    0.00043487548828125,
    0.01953125,
    0.03955078125,
    0.0262451171875,
    -0.048583984375,
    -0.0301513671875,
    0.0123291015625,
    -0.0026702880859375,
    -0.0252685546875,
    -0.00185394287109375,
    0.01611328125,
    0.0498046875,
    0.006591796875,
    -0.026611328125,
    0.01312255859375,
    -0.006591796875,
    0.01507568359375,
    0.0037689208984375,
    0.01104736328125,
    -0.0067138671875,
    -0.0089111328125,
    -0.00518798828125,
    -0.0032501220703125,
    -0.01190185546875,
    -0.01336669921875,
    -0.000896453857421875,
    -0.0458984375,
    0.00262451171875,
    0.0128173828125,
    -0.0184326171875,
    -0.03564453125,
    0.0242919921875,
    -0.004913330078125,
    -0.001373291015625,
    -0.046630859375,
    -0.004974365234375,
    0.046875,
    0.0008697509765625,
    0.00933837890625,
    -0.0185546875,
    0.0299072265625,
    -0.013427734375,
    0.00885009765625,
    0.01141357421875,
    0.015869140625,
    0.0130615234375,
    0.01104736328125,
    0.02392578125,
    -0.03271484375,
    0.0191650390625,
    0.0015411376953125,
    -0.00811767578125,
    -0.0130615234375,
    -0.059326171875,
    0.01129150390625,
    0.0238037109375,
    -0.0255126953125,
    -0.024658203125,
    0.00665283203125,
    -0.0098876953125,
    -0.03466796875,
    0.015380859375,
    0.004547119140625,
    -0.01202392578125,
    -0.0076904296875,
    -0.01312255859375,
    -0.0089111328125,
    -0.005706787109375,
    -0.006439208984375,
    -0.000949859619140625,
    -0.0185546875,
    -0.0184326171875,
    -0.034423828125,
    0.0208740234375,
    0.010986328125,
    -0.0225830078125,
    0.033447265625,
    -0.0233154296875,
    0.00110626220703125,
    -0.0498046875,
    -0.030517578125,
    0.039306640625,
    0.01171875,
    -0.0277099609375,
    0.0185546875,
    -0.0224609375,
    0.0181884765625,
    0.048095703125,
    -0.0303955078125,
    0.04345703125,
    -0.00653076171875,
    -0.003814697265625,
    0.0089111328125,
    -0.00518798828125,
    0.00384521484375,
    0.040771484375,
    0.040771484375,
    0.00836181640625,
    -0.009521484375,
    -0.00009775161743164062,
    -0.01019287109375,
    -0.005889892578125,
    0.0179443359375,
    0.01055908203125,
    0.0260009765625,
    0.00775146484375,
    0.015869140625,
    -0.01806640625,
    -0.00885009765625,
    0.0341796875,
    0.01953125,
    0.005523681640625,
    0.035400390625,
    -0.02490234375,
    0.0167236328125,
    0.0155029296875,
    0.02294921875,
    0.0181884765625,
    0.0198974609375,
    -0.00439453125,
    0.002410888671875,
    0.0264892578125,
    -0.02734375,
    -0.005218505859375,
    0.0181884765625,
    -0.0025787353515625,
    0.0252685546875,
    0.0191650390625,
    0.01190185546875,
    0.003326416015625,
    -0.0439453125,
    -0.0030059814453125,
    0.009521484375,
    -0.00457763671875,
    0.01495361328125,
    0.01043701171875,
    -0.0027923583984375,
    0.00726318359375,
    -0.017578125,
    0.034912109375,
    0.022216796875,
    0.012451171875,
    0.0016937255859375,
    0.014404296875,
    -0.06494140625,
    0.015380859375,
    0.016357421875,
    0.022216796875,
    -0.050537109375,
    -0.0118408203125,
    -0.0003299713134765625,
    0.00921630859375,
    -0.0205078125,
    -0.0034332275390625
  ],
  "created": "2025-06-12T05:14:14.234978",
  "count": 62
}