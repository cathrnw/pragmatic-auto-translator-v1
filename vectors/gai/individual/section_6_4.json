{
  "id": "section_6",
  "text": "STOCHASTIC PARROTS In this section, we explore the ways in which the factors laid out in §4 and §5 — the tendency of training data ingested from the Internet to encode hegemonic worldviews, the tendency of LMs to amplify biases and other issues in the training data, and the tendency of researchers and other people to mistake LM-driven performance gains for actual natural language understanding — present real-world risks of harm, as these technologies are deployed. After exploring some reasons why humans mistake LM output for meaningful text, we turn to the risks and harms from deploying such a model at scale. We find that the mix of human biases and seemingly coherent language heightens the potential for automation bias, deliberate misuse, and amplification of a hegemonic worldview. We focus primarily on cases where LMs are used in generating text, but we will also touch on risks that arise when LMs or word embeddings derived from them are components of systems for classification, query expansion, or other tasks, or when users can query LMs for information memorized from their training data. [Ref: §4 -> section_4] [Ref: §5 -> section_5] Coherence in the Eye of the Beholder Where traditional n-gram LMs [117] can only model relatively local dependencies, predicting each word given the preceding sequence of N words (usually 5 or fewer), the Transformer LMs capture much larger windows and can produce text that is seemingly not only fluent but also coherent even over paragraphs. For example, McGuffie and Newhouse [80] prompted GPT-3 with the text in bold in Figure 1, and it produced the rest of the text, including the Q&A format.21 This example illustrates GPT-3's ability to produce coherent and on-topic text; the topic is connected to McGuffie and Newhouse's study of GPT-3 in the context of extremism, discussed below. [Footnote 21]: This is just the first part of the response that McGuffie and Newhouse show. GPT-3 continues for two more question answer pairs with similar coherence. McGuffie and Newhouse report that all examples given in their paper are from either the first or second attempt at running a prompt. Citations: [[117]: ref_117] [[80]: ref_80] [Ref: Figure 1 -> figure_1] We say seemingly coherent because coherence is in fact in the eye of the beholder. Our human understanding of coherence derives from our ability to recognize interlocutors' beliefs [30, 31] and intentions [23, 33] within context [32]. That is, human language use takes place between individuals who share common ground and are mutually aware of that sharing (and its extent), who have communicative intents which they use language to convey, and who model each others' mental states as they communicate. As such, human communication relies on the interpretation of implicit meaning conveyed between individuals. The fact that human-human communication is a jointly constructed activity [29, 128] is most clearly true in co-situated spoken or signed communication, but we use the same facilities for producing language that is intended for audiences not co-present with us (readers, listeners, watchers at a distance in time or space) and in interpreting such language when we encounter it. It must follow that even when we don't know the person who generated the language we are interpreting, we build a partial model of who they are and what common ground we think they share with us, and use this in interpreting their words. Citations: [[30, 31]: ref_30, ref_31] [[23, 33]: ref_23, ref_33] [[32]: ref_32] [[29, 128]: ref_29, ref_128] Text generated by an LM is not grounded in communicative intent, any model of the world, or any model of the reader's state of mind. It can't have been, because the training data never included sharing thoughts with a listener, nor does the machine have the ability to do that. This can seem counter-intuitive given the increasingly fluent qualities of automatically generated text, but we have to account for the fact that our perception of natural language text, regardless of how it was generated, is mediated by our own linguistic competence and our predisposition to interpret communicative acts as conveying coherent meaning and intent, whether or not they do [89, 140]. The problem is, if one side of the communication does not have meaning, then the comprehension of the implicit meaning is an illusion arising from our singular human understanding of language (independent of the model).22 Contrary to how it may seem when we observe its output, an LM is a system for haphazardly stitching together sequences of linguistic forms it has observed in its vast training data, according to probabilistic information about how they combine, but without any reference to meaning: a stochastic parrot. [Footnote 22]: Controlled generation, where an LM is deployed within a larger system that guides its generation of output to certain styles or topics [e.g. 147, 151, 158], is not the same thing as communicative intent. One clear way to distinguish the two is to ask whether the system (or the organization deploying the system) has accountability for the truth of the utterances produced. Citations: [[89, 140]: ref_89, ref_140] Risks and Harms The ersatz fluency and coherence of LMs raises several risks, precisely because humans are prepared to interpret strings belonging to languages they speak as meaningful and corresponding to the communicative intent of some individual or group of individuals who have accountability for what is said. We now turn to examples, laying out the potential follow-on harms. The first risks we consider are the risks that follow from the LMs absorbing the hegemonic worldview from their training data. When humans produce language, our utterances reflect our worldviews, including our biases [78, 79]. As people in positions of privilege with respect to a society's racism, misogyny, ableism, etc., tend to be overrepresented in training data for LMs (as discussed in §4 above), this training data thus includes encoded biases, many already recognized as harmful. Citations: [[78, 79]: ref_78, ref_79] [Ref: §4 -> section_4] Biases can be encoded in ways that form a continuum from subtle patterns like referring to women doctors as if doctor itself entails not-woman or referring to both genders excluding the possibility of non-binary gender identities, through directly contested framings (e.g. undocumented immigrants vs. illegal immigrants or illegals), to language that is widely recognized to be derogatory (e.g. racial slurs) yet still used by some. While some of the most overtly derogatory words could be filtered out, not all forms of online abuse are easily detectable using such taboo words, as evidenced by the growing body of research on online abuse detection [45, 109]. Furthermore, in addition to abusive language [139] and hate speech [67], there are subtler forms of negativity such as gender bias [137], microaggressions [22], dehumanization [83], and various socio-political framing biases [44, 114] that are prevalent in language data. For example, describing a woman's account of her experience of sexism with the word tantrum both reflects a worldview where the sexist actions are normative and foregrounds a stereotype of women as childish and not in control of their emotions. Citations: [[45, 109]: ref_45, ref_109] [[139]: ref_139] [[67]: ref_67] [[137]: ref_137] [[22]: ref_22] [[83]: ref_83] [[44, 114]: ref_44, ref_114] An LM that has been trained on such data will pick up these kinds of problematic associations. If such an LM produces text that is put into the world for people to interpret (flagged as produced by an 'AI' or otherwise), what risks follow? In the first instance, we foresee that LMs producing text will reproduce and even amplify the biases in their input [53]. Thus the risk is that people disseminate text generated by LMs, meaning more text in the world that reinforces and propagates stereotypes and problematic associations, both to humans who encounter the text and to future LMs trained on training sets that ingested the previous generation LM's output. Humans who encounter this text may themselves be subjects of those stereotypes and associations or not. Either way, harms ensue: readers subject to the stereotypes may experience the psychological harms of microaggressions [88, 141] and stereotype threat [97, 126]. Other readers may be introduced to stereotypes or have ones they already carry reinforced, leading them to engage in discrimination (consciously or not) [55], which in turn leads to harms of subjugation, denigration, belittlement, loss of opportunity [3, 4, 56] and others on the part of those discriminated against. Citations: [[53]: ref_53] [[88, 141]: ref_88, ref_141] [[97, 126]: ref_97, ref_126] [[55]: ref_55] [[3, 4, 56]: ref_3, ref_4, ref_56] If the LM outputs overtly abusive language (as Gehman et al. [53] show that they can and do), then a similar set of risks arises. These include: propagating or proliferating overtly abusive views and associations, amplifying abusive language, and producing more (synthetic) abusive language that may be included in the next iteration of large-scale training data collection. The harms that could follow from these risks are again similar to those identified above for more subtly biased language, but perhaps more acute to the extent that the language in question is overtly violent or defamatory. They include the psychological harm experienced by those who identify with the categories being denigrated if they encounter the text; the reinforcement of sexist, racist, ableist, etc. ideology; follow-on effects of such reinforced ideologies (including violence); and harms to the reputation of any individual or organization perceived to be the source of the text. Citations: [[53]: ref_53] If the LM or word embeddings derived from it are used as components in a text classification system, these biases can lead to allocational and/or reputational harms, as biases in the representations affect system decisions [125]. This case is especially pernicious for being largely invisible to both the direct user of the system and any indirect stakeholders about whom decisions are being made. Similarly, biases in an LM used in query expansion could influence search results, further exacerbating the risk of harms of the type documented by Noble in [94], where the juxtaposition of search queries and search results, when connected by negative stereotypes, reinforce those stereotypes and cause psychological harm. Citations: [[125]: ref_125] [[94]: ref_94] The above cases involve risks that could arise when LMs are deployed without malicious intent. A third category of risk involves bad actors taking advantage of the ability of large LMs to produce large quantities of seemingly coherent texts on specific topics on demand in cases where those deploying the LM have no investment in the truth of the generated text. These include prosaic cases, such as services set up to 'automatically' write term papers or interact on social media,23 as well as use cases connected to promoting extremism. For example, McGuffie and Newhouse [80] show how GPT-3 could be used to generate text in the persona of a conspiracy theorist, which in turn could be used to populate extremist recruitment message boards. This would give such groups a cheap way to boost recruitment by making human targets feel like they were among many like-minded people. If the LMs are deployed in this way to recruit more people to extremist causes, then harms, in the first instance, befall the people so recruited and (likely more severely) to others as a result of violence carried out by the extremists. [Footnote 23]: Such as the GPT-3 powered bot let loose on Reddit; see https://thenextweb.com/neural/2020/10/07/someone-let-a-gpt-3-bot-loose-on-reddit-it-didnt-end-well/amp/. Citations: [[80]: ref_80] Yet another risk connected to seeming coherence and fluency involves machine translation (MT) and the way that increased fluency of MT output changes the perceived adequacy of that output [77]. This differs somewhat from the cases above in that there was an initial human communicative intent, by the author of the source language text. However, MT systems can (and frequently do) produce output that is inaccurate yet both fluent and (again, seemingly) coherent in its own right to a consumer who either doesn't see the source text or cannot understand the source text on their own. When such consumers therefore mistake the meaning attributed to the MT output as the actual communicative intent of the original text's author, real-world harm can ensue. A case in point is the story of a Palestinian man, arrested by Israeli police, after MT translated his Facebook post which said \"good morning\" (in Arabic) to \"hurt them\" (in English) and \"attack them\" (in Hebrew).24 This case involves a short phrase, but it is easy to imagine how the ability of large LMs to produce seemingly coherent text over larger passages could erase cues that might tip users off to translation errors in longer passages as well [77]. [Footnote 24]: https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israeltranslates-good-morning-attack-them-arrest Citations: [[77]: ref_77] Finally, we note that there are risks associated with the fact that LMs with extremely large numbers of parameters model their training data very closely and can be prompted to output specific information from that training data. For example, [28] demonstrate a methodology for extracting personally identifiable information (PII) from an LM and find that larger LMs are more susceptible to this style of attack than smaller ones. Building training data out of publicly available documents doesn't fully mitigate this risk: just because the PII was already available in the open on the Internet doesn't mean there isn't additional harm in collecting it and providing another avenue to its discovery. This type of risk differs from those noted above because it doesn't hinge on seeming coherence of synthetic text, but the possibility of a sufficiently motivated user gaining access to training data via the LM. In a similar vein, users might query LMs for 'dangerous knowledge' (e.g. tax avoidance advice), knowing that what they were getting was synthetic and therefore not credible but nonetheless representing clues to what is in the training data in order to refine their own search queries. Citations: [[28]: ref_28] Summary In this section, we have discussed how the human tendency to attribute meaning to text, in combination with large LMs' ability to learn patterns of forms that humans associate with various biases and other harmful attitudes, leads to risks of real-world harm, should LM-generated text be disseminated. We have also reviewed risks connected to using LMs as components in classification systems and the risks of LMs memorizing training data. We note that the risks associated with synthetic but seemingly coherent text are deeply connected to the fact that such synthetic text can enter into conversations without any person or entity being accountable for it. This accountability both involves responsibility for truthfulness and is important in situating meaning. As Maggie Nelson [92] writes: \"Words change depending on who speaks them; there is no cure.\" Citations: [[92]: ref_92] In §7, we consider directions the field could take to pursue goals of creating language technology while avoiding some of the risks and harms identified here and above. [Ref: §7 -> section_7]",
  "embedding": [
    0.1630859375,
    -0.1337890625,
    0.054443359375,
    -0.02294921875,
    0.07763671875,
    -0.01708984375,
    -0.056640625,
    0.06787109375,
    -0.032958984375,
    0.02001953125,
    -0.036376953125,
    0.10986328125,
    -0.0234375,
    -0.051025390625,
    0.034423828125,
    0.076171875,
    -0.0181884765625,
    0.006927490234375,
    -0.142578125,
    -0.006561279296875,
    -0.02734375,
    0.006011962890625,
    0.06591796875,
    0.0576171875,
    0.01171875,
    0.01239013671875,
    -0.107421875,
    -0.0888671875,
    -0.0191650390625,
    0.0380859375,
    0.0673828125,
    -0.0625,
    0.024658203125,
    -0.04931640625,
    0.0498046875,
    -0.052978515625,
    0.0947265625,
    -0.0015869140625,
    -0.0255126953125,
    -0.05322265625,
    0.003997802734375,
    0.01416015625,
    0.025634765625,
    0.0089111328125,
    0.0810546875,
    -0.0233154296875,
    0.068359375,
    0.0634765625,
    -0.0252685546875,
    0.0286865234375,
    -0.0164794921875,
    0.0908203125,
    -0.0206298828125,
    0.0023956298828125,
    0.041748046875,
    -0.0277099609375,
    -0.031494140625,
    0.00958251953125,
    -0.003570556640625,
    0.021728515625,
    -0.054931640625,
    0.03173828125,
    0.025390625,
    -0.0272216796875,
    -0.036376953125,
    0.006927490234375,
    0.000812530517578125,
    -0.07861328125,
    -0.00946044921875,
    -0.03173828125,
    -0.032470703125,
    0.060302734375,
    0.03271484375,
    0.08984375,
    -0.072265625,
    -0.01251220703125,
    -0.034423828125,
    -0.06640625,
    0.01080322265625,
    0.0027008056640625,
    0.14453125,
    -0.0181884765625,
    0.033203125,
    -0.06591796875,
    0.050048828125,
    0.055908203125,
    -0.0040283203125,
    -0.00750732421875,
    0.014404296875,
    -0.03076171875,
    0.0274658203125,
    -0.08935546875,
    0.005615234375,
    -0.05859375,
    0.000545501708984375,
    -0.01123046875,
    -0.046875,
    0.07763671875,
    0.029052734375,
    -0.0284423828125,
    -0.03515625,
    0.04736328125,
    -0.12109375,
    0.044677734375,
    -0.006988525390625,
    0.0189208984375,
    -0.00074005126953125,
    -0.0299072265625,
    -0.0303955078125,
    -0.05322265625,
    -0.02978515625,
    0.03173828125,
    -0.0081787109375,
    -0.047607421875,
    -0.00112152099609375,
    0.0380859375,
    0.0859375,
    0.056396484375,
    0.05078125,
    -0.046875,
    -0.04345703125,
    0.0001220703125,
    -0.00933837890625,
    0.0400390625,
    0.01434326171875,
    0.01263427734375,
    -0.05859375,
    -0.01483154296875,
    0.029296875,
    -0.05615234375,
    -0.05517578125,
    0.048828125,
    -0.041015625,
    0.003143310546875,
    0.00537109375,
    -0.060791015625,
    0.033203125,
    -0.0390625,
    -0.00653076171875,
    0.00885009765625,
    -0.0301513671875,
    0.0277099609375,
    -0.006561279296875,
    -0.037353515625,
    -0.0380859375,
    -0.07861328125,
    -0.01116943359375,
    -0.041015625,
    0.0166015625,
    -0.0341796875,
    0.0308837890625,
    -0.007049560546875,
    0.007568359375,
    0.06787109375,
    -0.03466796875,
    -0.047607421875,
    -0.02001953125,
    0.033203125,
    0.00034332275390625,
    0.040283203125,
    0.0228271484375,
    0.01446533203125,
    0.029052734375,
    0.017333984375,
    -0.0263671875,
    0.0230712890625,
    -0.047607421875,
    0.0174560546875,
    0.0291748046875,
    0.0023651123046875,
    -0.03466796875,
    0.0103759765625,
    0.0181884765625,
    0.001953125,
    -0.00122833251953125,
    -0.0120849609375,
    -0.0027313232421875,
    0.0751953125,
    0.01904296875,
    0.091796875,
    0.022216796875,
    -0.003936767578125,
    -0.01611328125,
    -0.0245361328125,
    -0.04296875,
    -0.020751953125,
    0.035888671875,
    -0.02685546875,
    0.00543212890625,
    -0.005035400390625,
    0.0089111328125,
    -0.00872802734375,
    0.03759765625,
    0.041259765625,
    0.04638671875,
    -0.0211181640625,
    -0.05224609375,
    0.00102996826171875,
    -0.0291748046875,
    -0.10302734375,
    -0.051025390625,
    -0.0302734375,
    0.0107421875,
    0.0081787109375,
    0.034912109375,
    0.0277099609375,
    -0.037841796875,
    -0.07861328125,
    0.00775146484375,
    0.0286865234375,
    -0.005950927734375,
    -0.0072021484375,
    0.033203125,
    0.0130615234375,
    -0.05615234375,
    -0.01806640625,
    0.01318359375,
    0.061767578125,
    0.0439453125,
    0.01263427734375,
    0.01458740234375,
    0.039794921875,
    0.0294189453125,
    0.01300048828125,
    0.0155029296875,
    -0.005584716796875,
    0.01708984375,
    0.030517578125,
    0.002410888671875,
    -0.00970458984375,
    0.027587890625,
    0.0052490234375,
    0.039306640625,
    0.017333984375,
    0.01385498046875,
    0.0087890625,
    -0.0341796875,
    0.0206298828125,
    0.07666015625,
    -0.056884765625,
    -0.00860595703125,
    -0.01019287109375,
    -0.034912109375,
    0.036865234375,
    -0.0712890625,
    0.0032501220703125,
    -0.04052734375,
    -0.064453125,
    -0.0101318359375,
    -0.007537841796875,
    0.029296875,
    -0.0181884765625,
    -0.09912109375,
    -0.0238037109375,
    0.017578125,
    -0.044677734375,
    0.0184326171875,
    -0.047607421875,
    -0.0179443359375,
    -0.005523681640625,
    -0.0245361328125,
    -0.03076171875,
    -0.00013256072998046875,
    -0.000301361083984375,
    -0.0179443359375,
    0.008056640625,
    -0.01953125,
    -0.003387451171875,
    0.0064697265625,
    -0.10302734375,
    -0.01171875,
    -0.06591796875,
    -0.035400390625,
    0.0235595703125,
    0.0218505859375,
    0.0252685546875,
    -0.037841796875,
    0.0032196044921875,
    -0.0166015625,
    -0.010009765625,
    -0.033203125,
    -0.0159912109375,
    0.03271484375,
    0.0002651214599609375,
    -0.00592041015625,
    0.019287109375,
    0.0079345703125,
    0.002105712890625,
    -0.01446533203125,
    0.0186767578125,
    0.005523681640625,
    -0.0439453125,
    0.0023040771484375,
    -0.05322265625,
    -0.0244140625,
    0.023193359375,
    -0.05224609375,
    0.00128173828125,
    0.05517578125,
    0.00970458984375,
    -0.049560546875,
    0.0289306640625,
    0.01519775390625,
    0.045166015625,
    0.00052642822265625,
    -0.0235595703125,
    0.013671875,
    0.01080322265625,
    -0.0244140625,
    0.00909423828125,
    -0.0157470703125,
    -0.0196533203125,
    -0.030517578125,
    0.0115966796875,
    -0.0250244140625,
    0.00154876708984375,
    -0.0223388671875,
    0.0225830078125,
    -0.02685546875,
    -0.00433349609375,
    0.01123046875,
    -0.031982421875,
    -0.012451171875,
    0.01068115234375,
    -0.028076171875,
    -0.059326171875,
    0.0029144287109375,
    -0.0162353515625,
    -0.0032806396484375,
    -0.01446533203125,
    -0.0037841796875,
    0.0013427734375,
    0.007598876953125,
    0.051025390625,
    0.0069580078125,
    -0.010986328125,
    -0.061279296875,
    -0.0238037109375,
    0.05615234375,
    0.021728515625,
    0.0274658203125,
    -0.01116943359375,
    0.016357421875,
    -0.013427734375,
    0.0228271484375,
    0.0419921875,
    -0.02587890625,
    -0.01458740234375,
    0.0140380859375,
    0.04638671875,
    0.025634765625,
    0.0159912109375,
    0.010986328125,
    -0.009033203125,
    0.0172119140625,
    0.004425048828125,
    -0.02587890625,
    0.0007781982421875,
    0.0299072265625,
    -0.044189453125,
    -0.0128173828125,
    -0.0303955078125,
    -0.031982421875,
    0.05419921875,
    0.0203857421875,
    0.039306640625,
    0.009765625,
    0.0250244140625,
    -0.0216064453125,
    0.025146484375,
    -0.005218505859375,
    0.00714111328125,
    0.033935546875,
    0.0419921875,
    0.01263427734375,
    0.0439453125,
    0.0380859375,
    0.005126953125,
    0.06884765625,
    -0.010986328125,
    0.002105712890625,
    0.00213623046875,
    0.05078125,
    0.0277099609375,
    0.035888671875,
    0.0016937255859375,
    0.07568359375,
    -0.0556640625,
    -0.012451171875,
    0.0211181640625,
    -0.012451171875,
    0.0274658203125,
    0.052490234375,
    -0.01141357421875,
    -0.036376953125,
    0.0220947265625,
    0.0751953125,
    0.0009765625,
    -0.00013446807861328125,
    0.033203125,
    0.00506591796875,
    0.01177978515625,
    0.01263427734375,
    -0.049560546875,
    0.02197265625,
    -0.006317138671875,
    0.0361328125,
    -0.003021240234375,
    0.0069580078125,
    -0.048095703125,
    -0.02099609375,
    -0.004486083984375,
    -0.044921875,
    -0.03369140625,
    -0.0123291015625,
    -0.040283203125,
    -0.0186767578125,
    0.050537109375,
    -0.009765625,
    0.0045166015625,
    0.003936767578125,
    0.044677734375,
    -0.0157470703125,
    -0.01300048828125,
    0.02587890625,
    -0.0081787109375,
    -0.01300048828125,
    -0.0201416015625,
    -0.0023651123046875,
    0.0152587890625,
    -0.02783203125,
    -0.0142822265625,
    -0.0194091796875,
    0.00238037109375,
    -0.020263671875,
    -0.02197265625,
    -0.0244140625,
    0.0115966796875,
    0.0042724609375,
    0.0208740234375,
    0.0179443359375,
    0.0274658203125,
    0.02978515625,
    -0.025390625,
    0.0223388671875,
    0.02734375,
    0.04736328125,
    -0.0277099609375,
    -0.00189971923828125,
    -0.01190185546875,
    -0.0086669921875,
    0.054443359375,
    -0.05322265625,
    -0.0247802734375,
    -0.0208740234375,
    0.01031494140625,
    0.050537109375,
    0.003326416015625,
    0.017578125,
    0.051513671875,
    0.01708984375,
    -0.0089111328125,
    0.04443359375,
    -0.05615234375,
    0.0654296875,
    0.0135498046875,
    0.053955078125,
    0.06396484375,
    0.0240478515625,
    -0.027099609375,
    0.0218505859375,
    0.03271484375,
    0.004425048828125,
    -0.0322265625,
    -0.01190185546875,
    0.025390625,
    -0.047119140625,
    -0.00982666015625,
    0.000850677490234375,
    -0.0086669921875,
    -0.0184326171875,
    -0.0115966796875,
    0.0213623046875,
    0.035400390625,
    -0.002105712890625,
    -0.0157470703125,
    0.0201416015625,
    -0.02294921875,
    -0.046875,
    -0.00469970703125,
    -0.0164794921875,
    -0.007720947265625,
    -0.015380859375,
    0.01275634765625,
    0.01263427734375,
    0.01220703125,
    -0.0015411376953125,
    -0.00384521484375,
    -0.0281982421875,
    -0.047607421875,
    -0.0235595703125,
    -0.022216796875,
    -0.038330078125,
    -0.0208740234375,
    -0.003997802734375,
    -0.026611328125,
    -0.0279541015625,
    -0.009765625,
    0.01531982421875,
    0.006072998046875,
    -0.002593994140625,
    0.03564453125,
    0.036376953125,
    -0.009033203125,
    0.010986328125,
    0.0279541015625,
    0.02294921875,
    -0.01361083984375,
    -0.011474609375,
    0.01361083984375,
    0.0037384033203125,
    -0.005584716796875,
    0.04736328125,
    -0.039794921875,
    -0.00634765625,
    0.015869140625,
    -0.0169677734375,
    0.0286865234375,
    0.056396484375,
    -0.01092529296875,
    0.01446533203125,
    0.018798828125,
    0.0042724609375,
    -0.0235595703125,
    0.00107574462890625,
    0.00860595703125,
    -0.0208740234375,
    -0.039306640625,
    0.008544921875,
    0.0048828125,
    -0.0103759765625,
    -0.033203125,
    -0.05712890625,
    -0.0283203125,
    0.007293701171875,
    -0.0216064453125,
    0.022705078125,
    0.046630859375,
    0.019287109375,
    0.02880859375,
    -0.0228271484375,
    0.0308837890625,
    0.009521484375,
    0.01104736328125,
    0.0048828125,
    -0.026611328125,
    -0.000576019287109375,
    -0.0390625,
    -0.037353515625,
    0.0146484375,
    0.0135498046875,
    -0.0224609375,
    -0.0072021484375,
    -0.023681640625,
    -0.0140380859375,
    -0.01513671875,
    -0.0029449462890625,
    -0.005859375,
    0.005157470703125,
    0.015625,
    -0.040771484375,
    -0.0245361328125,
    0.00885009765625,
    -0.005279541015625,
    0.0024566650390625,
    0.015625,
    0.0021820068359375,
    0.041015625,
    0.00811767578125,
    -0.0034332275390625,
    -0.0057373046875,
    -0.01251220703125,
    -0.0211181640625,
    0.06298828125,
    -0.028076171875,
    0.0026092529296875,
    0.0179443359375,
    -0.03515625,
    -0.0172119140625,
    0.0086669921875,
    -0.0022430419921875,
    -0.0306396484375,
    0.011474609375,
    -0.0086669921875,
    0.059326171875,
    0.01287841796875,
    -0.0439453125,
    -0.04541015625,
    -0.016357421875,
    -0.0111083984375,
    -0.0296630859375,
    -0.0115966796875,
    0.00848388671875,
    0.0035552978515625,
    0.00933837890625,
    0.057861328125,
    0.0150146484375,
    0.038818359375,
    -0.027587890625,
    -0.049072265625,
    0.0194091796875,
    -0.01007080078125,
    0.0225830078125,
    0.0030670166015625,
    0.045654296875,
    0.01220703125,
    0.01495361328125,
    -0.01483154296875,
    -0.01904296875,
    0.004913330078125,
    -0.00640869140625,
    0.019775390625,
    0.0341796875,
    0.021484375,
    0.01348876953125,
    0.0294189453125,
    0.033203125,
    0.039794921875,
    -0.006011962890625,
    0.03369140625,
    -0.040283203125,
    0.042236328125,
    0.009765625,
    -0.0181884765625,
    -0.0123291015625,
    0.01177978515625,
    0.06591796875,
    0.005401611328125,
    0.04150390625,
    -0.0036773681640625,
    0.0115966796875,
    -0.0098876953125,
    0.055419921875,
    0.00555419921875,
    -0.03271484375,
    -0.03125,
    0.0133056640625,
    -0.01611328125,
    -0.0194091796875,
    -0.005584716796875,
    -0.041259765625,
    0.0235595703125,
    0.0023193359375,
    0.01153564453125,
    0.006317138671875,
    0.00909423828125,
    -0.019287109375,
    0.029052734375,
    -0.02783203125,
    -0.035400390625,
    0.0260009765625,
    -0.023681640625,
    0.02880859375,
    -0.0150146484375,
    -0.031494140625,
    -0.0181884765625,
    0.00604248046875,
    0.0179443359375,
    -0.041259765625,
    0.03271484375,
    -0.0133056640625,
    0.02490234375,
    0.0235595703125,
    -0.0419921875,
    -0.01019287109375,
    0.0186767578125,
    -0.00122833251953125,
    0.0224609375,
    0.035888671875,
    -0.0081787109375,
    0.0017547607421875,
    0.0185546875,
    -0.015869140625,
    -0.0027313232421875,
    0.01446533203125,
    0.00177764892578125,
    -0.04296875,
    0.000743865966796875,
    -0.01361083984375,
    0.01171875,
    -0.0205078125,
    0.00244140625,
    0.017822265625,
    -0.001373291015625,
    0.0274658203125,
    -0.00933837890625,
    0.0208740234375,
    0.0107421875,
    0.01123046875,
    -0.0174560546875,
    -0.035400390625,
    0.020751953125,
    0.017578125,
    -0.017578125,
    0.004669189453125,
    0.0245361328125,
    0.0098876953125,
    0.0157470703125,
    0.01226806640625,
    0.032470703125,
    0.00274658203125,
    -0.0191650390625,
    0.00885009765625,
    -0.0030975341796875,
    0.0069580078125,
    -0.014404296875,
    0.00909423828125,
    -0.06689453125,
    0.00634765625,
    0.015380859375,
    0.0240478515625,
    -0.00469970703125,
    0.0022125244140625,
    -0.0289306640625,
    -0.01434326171875,
    0.01171875,
    0.03271484375,
    0.03173828125,
    -0.032958984375,
    -0.01708984375,
    -0.023681640625,
    -0.0179443359375,
    -0.0189208984375,
    -0.0064697265625,
    -0.01397705078125,
    -0.00469970703125,
    0.00872802734375,
    -0.001312255859375,
    0.0019683837890625,
    -0.041748046875,
    0.01904296875,
    0.01409912109375,
    -0.026611328125,
    0.029296875,
    -0.00007104873657226562,
    -0.031005859375,
    0.019287109375,
    -0.0054931640625,
    0.010986328125,
    -0.040283203125,
    0.00982666015625,
    0.02685546875,
    -0.0157470703125,
    -0.01287841796875,
    -0.01092529296875,
    -0.02099609375,
    -0.00156402587890625,
    0.0017547607421875,
    -0.0164794921875,
    -0.0216064453125,
    -0.0380859375,
    0.04931640625,
    0.0301513671875,
    0.042724609375,
    -0.040771484375,
    0.00677490234375,
    0.024658203125,
    -0.0089111328125,
    0.0145263671875,
    0.026611328125,
    -0.005706787109375,
    0.007049560546875,
    0.00848388671875,
    0.00049591064453125,
    0.0194091796875,
    0.017333984375,
    -0.00145721435546875,
    -0.004852294921875,
    -0.016357421875,
    0.005401611328125,
    -0.0277099609375,
    -0.0186767578125,
    -0.04052734375,
    0.00994873046875,
    0.01300048828125,
    0.003814697265625,
    0.01007080078125,
    0.01953125,
    -0.0556640625,
    0.0172119140625,
    0.006134033203125,
    -0.0211181640625,
    -0.005767822265625,
    0.027099609375,
    -0.04296875,
    0.0322265625,
    -0.026611328125,
    0.007415771484375,
    0.01116943359375,
    0.0185546875,
    0.047607421875,
    0.0003986358642578125,
    -0.0021514892578125,
    0.002593994140625,
    0.00958251953125,
    0.03466796875,
    -0.0322265625,
    -0.020751953125,
    0.024658203125,
    -0.01092529296875,
    0.014404296875,
    0.02490234375,
    0.002716064453125,
    -0.0101318359375,
    0.01165771484375,
    -0.01226806640625,
    -0.0272216796875,
    -0.017333984375,
    0.00372314453125,
    0.002685546875,
    -0.020263671875,
    0.0205078125,
    -0.03564453125,
    0.018798828125,
    -0.037841796875,
    0.021484375,
    -0.000759124755859375,
    0.0047607421875,
    -0.00994873046875,
    0.032958984375,
    -0.013671875,
    0.044189453125,
    -0.05419921875,
    0.00677490234375,
    -0.00958251953125,
    0.01324462890625,
    -0.05078125,
    0.01007080078125,
    0.0052490234375,
    -0.0218505859375,
    -0.0133056640625,
    -0.0137939453125,
    -0.0030670166015625,
    0.046875,
    -0.0294189453125,
    0.0235595703125,
    -0.0235595703125,
    0.0027923583984375,
    -0.007415771484375,
    0.01531982421875,
    0.01458740234375,
    0.0064697265625,
    0.007080078125,
    -0.023193359375,
    -0.016357421875,
    -0.01409912109375,
    0.0031890869140625,
    0.00677490234375,
    -0.00872802734375,
    0.0022430419921875,
    -0.01495361328125,
    -0.0247802734375,
    -0.040283203125,
    -0.01513671875,
    0.023193359375,
    0.037109375,
    -0.0159912109375,
    -0.0035552978515625,
    0.01226806640625,
    0.0208740234375,
    0.02783203125,
    0.0220947265625,
    0.02294921875,
    -0.0128173828125,
    -0.0185546875,
    -0.01446533203125,
    -0.005126953125,
    0.00799560546875,
    -0.00095367431640625,
    0.01025390625,
    0.0213623046875,
    0.035400390625,
    -0.01226806640625,
    0.01226806640625,
    0.052978515625,
    0.02880859375,
    0.0361328125,
    -0.006256103515625,
    -0.033203125,
    0.00005173683166503906,
    -0.01318359375,
    -0.0269775390625,
    -0.02490234375,
    -0.035888671875,
    -0.035888671875,
    -0.013916015625,
    -0.03564453125,
    -0.0245361328125,
    0.007476806640625,
    -0.0196533203125,
    -0.024658203125,
    -0.0028076171875,
    -0.01123046875,
    -0.0001926422119140625,
    -0.00799560546875,
    -0.00433349609375,
    0.015625,
    -0.0081787109375,
    0.01513671875,
    -0.0108642578125,
    0.043701171875,
    -0.00885009765625,
    0.0016326904296875,
    0.04736328125,
    -0.033203125,
    0.044921875,
    0.010986328125,
    0.021728515625,
    -0.0361328125,
    -0.0042724609375,
    -0.0035552978515625,
    0.02685546875,
    -0.0230712890625,
    -0.060791015625,
    -0.020263671875,
    0.0211181640625,
    0.008056640625,
    -0.0074462890625,
    0.00087738037109375,
    -0.00616455078125,
    -0.00012302398681640625,
    0.02685546875,
    0.056884765625,
    -0.0069580078125,
    0.00640869140625,
    -0.0093994140625,
    -0.0283203125,
    0.0036468505859375,
    -0.017333984375,
    0.060791015625,
    0.005096435546875,
    0.0145263671875,
    -0.00872802734375,
    0.01361083984375,
    0.0111083984375,
    -0.01092529296875,
    0.01318359375,
    -0.026611328125,
    -0.015625,
    -0.00121307373046875,
    -0.0013427734375,
    -0.017578125,
    -0.01544189453125,
    -0.01153564453125,
    -0.01220703125,
    0.00885009765625,
    0.05322265625,
    0.004058837890625,
    -0.047607421875,
    0.0042724609375,
    -0.003509521484375,
    0.01361083984375,
    0.0203857421875,
    0.0189208984375,
    -0.0233154296875,
    -0.0111083984375,
    0.0289306640625,
    0.0128173828125,
    -0.006622314453125,
    0.046142578125,
    0.0284423828125,
    -0.033447265625,
    -0.0201416015625,
    0.0218505859375,
    -0.0030975341796875,
    -0.027099609375,
    0.0040283203125,
    0.01116943359375,
    -0.0087890625,
    0.0159912109375,
    0.019287109375,
    -0.0135498046875,
    0.06494140625,
    -0.0303955078125,
    0.02587890625,
    0.028564453125,
    0.032470703125,
    -0.014892578125,
    0.000782012939453125,
    0.01190185546875,
    -0.0089111328125,
    0.0203857421875,
    -0.01129150390625,
    -0.0003986358642578125,
    -0.0286865234375,
    -0.0118408203125,
    0.037841796875,
    0.0125732421875,
    0.01519775390625,
    -0.038818359375,
    -0.0189208984375,
    -0.050048828125,
    0.007080078125,
    -0.0022125244140625,
    0.03564453125,
    0.01043701171875,
    0.005340576171875,
    0.007080078125,
    0.0020294189453125,
    -0.020751953125,
    0.032958984375,
    -0.004638671875,
    0.0142822265625,
    0.037841796875,
    -0.006744384765625,
    0.004058837890625,
    0.032470703125,
    -0.003997802734375,
    -0.050048828125,
    -0.038330078125,
    -0.0014190673828125,
    -0.007598876953125,
    0.00994873046875,
    -0.00142669677734375
  ],
  "created": "2025-06-12T05:14:14.234978",
  "count": 33
}