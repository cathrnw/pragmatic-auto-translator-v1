{
  "id": "section_4",
  "text": "UNFATHOMABLE TRAINING DATA The size of data available on the web has enabled deep learning models to achieve high accuracy on specific benchmarks in NLP and computer vision applications. However, in both application areas, the training data has been shown to have problematic characteristics [18, 38, 42, 47, 61] resulting in models that encode stereotypical and derogatory associations along gender, race, ethnicity, and disability status [11, 12, 69, 69, 132, 132, 157]. In this section, we discuss how large, uncurated, Internet-based datasets encode the dominant/hegemonic view, which further harms people at the margins, and recommend significant resource allocation towards dataset curation and documentation practices. Citations: [[18, 38, 42, 47, 61]: ref_18, ref_38, ref_42, ref_47, ref_61] [[11, 12, 69, 69, 132, 132, 157]: ref_11, ref_12, ref_69, ref_69, ref_132, ref_132, ref_157] Size Doesn't Guarantee Diversity The Internet is a large and diverse virtual space, and accordingly, it is easy to imagine that very large datasets, such as Common Crawl (\"petabytes of data collected over 8 years of web crawling\",11 a filtered version of which is included in the GPT-3 training data) must therefore be broadly representative of the ways in which different people view the world. However, on closer examination, we find that there are several factors which narrow Internet participation, the discussions which will be included via the crawling methodology, and finally the texts likely to be contained after the crawled data are filtered. In all cases, the voices of people most likely to hew to a hegemonic viewpoint are also more likely to be retained. In the case of US and UK English, this means that white supremacist and misogynistic, ageist, etc. views are overrepresented in the training data, not only exceeding their prevalence in the general population but also setting up models trained on these datasets to further amplify biases and harms. [Footnote 11]: http://commoncrawl.org/ Starting with who is contributing to these Internet text collections, we see that Internet access itself is not evenly distributed, resulting in Internet data overrepresenting younger users and those from developed countries [100, 143].12 However, it's not just the Internet as a whole that is in question, but rather specific subsamples of it. For instance, GPT-2's training data is sourced by scraping outbound links from Reddit, and Pew Internet Research's 2016 survey reveals 67% of Reddit users in the United States are men, and 64% between ages 18 and 29.13 Similarly, recent surveys of Wikipedians find that only 8.8–15% are women or girls [9]. [Footnote 12]: This point is also mentioned in the model card for GPT-3: https://github.com/openai/gpt-3/blob/master/model-card.md [Footnote 13]: https://www.journalism.org/2016/02/25/reddit-news-users-more-likely-to-be-maleyoung-and-digital-in-their-news-preferences/ Citations: [[100, 143]: ref_100, ref_143] [[9]: ref_9] Furthermore, while user-generated content sites like Reddit, Twitter, and Wikipedia present themselves as open and accessible to anyone, there are structural factors including moderation practices which make them less welcoming to marginalized populations. Jones [64] documents (using digital ethnography techniques [63]) multiple cases where people on the receiving end of death threats on Twitter have had their accounts suspended while the accounts issuing the death threats persist. She further reports that harassment on Twitter is experienced by \"a wide range of overlapping groups including domestic abuse victims, sex workers, trans people, queer people, immigrants, medical patients (by their providers), neurodivergent people, and visibly or vocally disabled people.\" The net result is that a limited set of subpopulations can continue to easily add data, sharing their thoughts and developing platforms that are inclusive of their worldviews; this systemic pattern in turn worsens diversity and inclusion within Internet-based communication, creating a feedback loop that lessens the impact of data from underrepresented populations. Citations: [[64]: ref_64] [[63]: ref_63] Even if populations who feel unwelcome in mainstream sites set up different fora for communication, these may be less likely to be included in training data for language models. Take, for example, older adults in the US and UK. Lazar et al. outline how they both individually and collectively articulate anti-ageist frames specifically through blogging [71], which some older adults prefer over more popular social media sites for discussing sensitive topics [24]. These fora contain rich discussions about what constitutes age discrimination and the impacts thereof. However, a blogging community such as the one described by Lazar et al. is less likely to be found than other blogs that have more incoming and outgoing links. Citations: [[71]: ref_71] [[24]: ref_24] Finally, the current practice of filtering datasets can further attenuate the voices of people from marginalized identities. The training set for GPT-3 was a filtered version of the Common Crawl dataset, developed by training a classifier to pick out those documents most similar to the ones used in GPT-2's training data, i.e. documents linked to from Reddit [25], plus Wikipedia and a collection of books. While this was reportedly effective at filtering out documents that previous work characterized as \"unintelligible\" [134], what is unmeasured (and thus unknown) is what else it filtered out. The Colossal Clean Crawled Corpus [107], used to train a trillion parameter LM in [43], is cleaned, inter alia, by discarding any page containing one of a list of about 400 \"Dirty, Naughty, Obscene or Otherwise Bad Words\" [p.6].14 This list is overwhelmingly words related to sex, with a handful of racial slurs and words related to white supremacy (e.g. swastika, white power) included. While possibly effective at removing documents containing pornography (and the associated problematic stereotypes encoded in the language of such sites [125]) and certain kinds of hate speech, this approach will also undoubtedly attenuate, by suppressing such words as twink, the influence of online spaces built by and for LGBTQ people.15 If we filter out the discourse of marginalized populations, we fail to provide training data that reclaims slurs and otherwise describes marginalized identities in a positive light. [Footnote 14]: Available at https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-andOtherwise-Bad-Words/blob/master/en, accessed Jan 18, 2021 [Footnote 15]: This observation is due to William Agnew. Citations: [[25]: ref_25] [[134]: ref_134] [[107]: ref_107] [[43]: ref_43] [[125]: ref_125] Thus at each step, from initial participation in Internet fora, to continued presence there, to the collection and finally the filtering of training data, current practice privileges the hegemonic viewpoint. In accepting large amounts of web text as 'representative' of 'all' of humanity we risk perpetuating dominant viewpoints, increasing power imbalances, and further reifying inequality. We instead propose practices that actively seek to include communities underrepresented on the Internet. For instance, one can take inspiration from movements to decolonize education by moving towards oral histories due to the overrepresentation of colonial views in text [35, 76, 127], and curate training datasets through a thoughtful process of deciding what to put in, rather than aiming solely for scale and trying haphazardly to weed out, post-hoc, flotsam deemed 'dangerous', 'unintelligible', or 'otherwise bad'. Citations: [[35, 76, 127]: ref_35, ref_76, ref_127] Static Data/Changing Social Views A central aspect of social movement formation involves using language strategically to destabilize dominant narratives and call attention to underrepresented social perspectives. Social movements produce new norms, language, and ways of communicating. This adds challenges to the deployment of LMs, as methodologies reliant on LMs run the risk of 'value-lock', where the LM-reliant technology reifies older, less-inclusive understandings. For instance, the Black Lives Matter movement (BLM) influenced Wikipedia article generation and editing such that, as the BLM movement grew, articles covering shootings of Black people increased in coverage and were generated with reduced latency [135]. Importantly, articles describing past shootings and incidents of police brutality were created and updated as articles for new events were created, reflecting how social movements make connections between events in time to form cohesive narratives [102]. More generally, Twyman et al. [135] highlight how social movements actively influence framings and reframings of minority narratives in the type of online discourse that potentially forms the data that underpins LMs. Citations: [[135]: ref_135] [[102]: ref_102] An important caveat is that social movements which are poorly documented and which do not receive significant media attention will not be captured at all. Media coverage can fail to cover protest events and social movements [41, 96] and can distort events that challenge state power [36]. This is exemplified by media outlets that tend to ignore peaceful protest activity and instead focus on dramatic or violent events that make for good television but nearly always result in critical coverage [81]. As a result, the data underpinning LMs stands to misrepresent social movements and disproportionately align with existing regimes of power. Citations: [[41, 96]: ref_41, ref_96] [[36]: ref_36] [[81]: ref_81] Developing and shifting frames stand to be learned in incomplete ways or lost in the big-ness of data used to train large LMs — particularly if the training data isn't continually updated. Given the compute costs alone of training large LMs, it likely isn't feasible for even large corporations to fully retrain them frequently enough to keep up with the kind of language change discussed here. Perhaps fine-tuning approaches could be used to retrain LMs, but here again, what would be required is thoughtful curation practices to find appropriate data to capture reframings and techniques for evaluating whether such fine-tuning appropriately captures the ways in which new framings contest hegemonic representations. Encoding Bias It is well established by now that large LMs exhibit various kinds of bias, including stereotypical associations [11, 12, 69, 119, 156, 157], or negative sentiment towards specific groups [61]. Furthermore, we see the effects of intersectionality [34], where BERT, ELMo, GPT and GPT-2 encode more bias against identities marginalized along more than one dimension than would be expected based on just the combination of the bias along each of the axes [54, 132]. Many of these works conclude that these issues are a reflection of training data characteristics. For instance, Hutchinson et al. find that BERT associates phrases referencing persons with disabilities with more negative sentiment words, and that gun violence, homelessness, and drug addiction are overrepresented in texts discussing mental illness [61]. Similarly, Gehman et al. show that models like GPT-3 trained with at least 570GB of data derived mostly from Common Crawl 16 can generate sentences with high toxicity scores even when prompted with non-toxic sentences [53]. Their investigation of GPT-2's training data 17 also finds 272K documents from unreliable news sites and 63K from banned subreddits. [Footnote 16]: https://commoncrawl.org/the-data/ [Footnote 17]: GPT-3’s training data is not openly available, but GPT-2’s training data was used indirectly to construct GPT-3’s [53]. Citations: [[11, 12, 69, 119, 156, 157]: ref_11, ref_12, ref_69, ref_119, ref_156, ref_157] [[61]: ref_61] [[34]: ref_34] [[54, 132]: ref_54, ref_132] [[61]: ref_61] [[53]: ref_53] These demonstrations of biases learned by LMs are extremely valuable in pointing out the potential for harm when such models are deployed, either in generating text or as components of classification systems, as explored further in §6. However, they do not represent a methodology that can be used to exhaustively discover all such risks, for several reasons. [Ref: §6 -> section_6] First, model auditing techniques typically rely on automated systems for measuring sentiment, toxicity, or novel metrics such as 'regard' to measure attitudes towards a specific demographic group [119]. But these systems themselves may not be reliable means of measuring the toxicity of text generated by LMs. For example, the Perspective API model has been found to associate higher levels of toxicity with sentences containing identity markers for marginalized groups or even specific names [61, 103]. Citations: [[119]: ref_119] [[61, 103]: ref_61, ref_103] Second, auditing an LM for biases requires an a priori understanding of what social categories might be salient. The works cited above generally start from US protected attributes such as race and gender (as understood within the US). But, of course, protected attributes aren't the only identity characteristics that can be subject to bias or discrimination, and the salient identity characteristics and expressions of bias are also culture-bound [46, 116]. Thus, components like toxicity classifiers would need culturally appropriate training data for each context of audit, and even still we may miss marginalized identities if we don't know what to audit for. Citations: [[46, 116]: ref_46, ref_116] Finally, we note that moving beyond demonstrating the existence of bias to building systems that verify the 'safety' of some LM (even for a given protected class) requires engaging with the systems of power that lead to the harmful outcomes such a system would seek to prevent [19]. For example, the #MeToo movement has spurred broad-reaching conversations about inappropriate sexual behavior from men in power, as well as men more generally [84]. These conversations challenge behaviors that have been historically considered appropriate or even the fault of women, shifting notions of sexually inappropriate behavior. Any product development that involves operationalizing definitions around such shifting topics into algorithms is necessarily political (whether or not developers choose the path of maintaining the status quo ante). For example, men and women make significantly different assessments of sexual harassment online [40]. An algorithmic definition of what constitutes inappropriately sexual communication will inherently be concordant with some views and discordant with others. Thus, an attempt to measure the appropriateness of text generated by LMs, or the biases encoded by a system, always needs to be done in relation to particular social contexts and marginalized perspectives [19]. Citations: [[19]: ref_19] [[84]: ref_84] [[40]: ref_40] Curation, Documentation & Accountability In summary, LMs trained on large, uncurated, static datasets from the Web encode hegemonic views that are harmful to marginalized populations. We thus emphasize the need to invest significant resources into curating and documenting LM training data. In this, we follow Jo et al. [62], who cite archival history data collection methods as an example of the amount of resources that should be dedicated to this process, and Birhane and Prabhu [18], who call for a more justice-oriented data collection methodology. Birhane and Prabhu note, echoing Ruha Benjamin [15], \"Feeding AI systems on the world's beauty, ugliness, and cruelty, but expecting it to reflect only the beauty is a fantasy.\" [p.1541] Citations: [[62]: ref_62] [[18]: ref_18] [[15]: ref_15] When we rely on ever larger datasets we risk incurring documentation debt,18 i.e. putting ourselves in a situation where the datasets are both undocumented and too large to document post hoc. While documentation allows for potential accountability [13, 52, 86], undocumented training data perpetuates harm without recourse. Without documentation, one cannot try to understand training data characteristics in order to mitigate some of these attested issues or even unknown ones. The solution, we propose, is to budget for documentation as part of the planned costs of dataset creation, and only collect as much data as can be thoroughly documented within that budget. [Footnote 18]: On the notion of documentation debt as applied to code, rather than data, see [154]. Citations: [[13, 52, 86]: ref_13, ref_52, ref_86]",
  "embedding": [
    0.1416015625,
    -0.20703125,
    0.0390625,
    -0.0191650390625,
    0.0185546875,
    0.0030975341796875,
    -0.1005859375,
    -0.02197265625,
    -0.0118408203125,
    0.018798828125,
    -0.028564453125,
    0.10986328125,
    -0.030517578125,
    -0.0289306640625,
    0.0849609375,
    0.036865234375,
    -0.09326171875,
    0.016357421875,
    -0.0634765625,
    -0.07275390625,
    -0.018798828125,
    -0.046875,
    0.07177734375,
    0.0341796875,
    0.05126953125,
    0.0206298828125,
    -0.119140625,
    -0.087890625,
    -0.0849609375,
    0.058349609375,
    0.12255859375,
    -0.11083984375,
    0.034423828125,
    -0.06494140625,
    -0.0240478515625,
    -0.037353515625,
    0.10546875,
    -0.0294189453125,
    0.0032501220703125,
    -0.0240478515625,
    -0.0029296875,
    0.039306640625,
    0.0040283203125,
    -0.04638671875,
    0.11328125,
    0.04052734375,
    0.040771484375,
    0.0142822265625,
    0.032958984375,
    0.000518798828125,
    -0.00408935546875,
    0.099609375,
    -0.004150390625,
    0.0211181640625,
    -0.0294189453125,
    0.003021240234375,
    0.087890625,
    -0.029541015625,
    0.0033111572265625,
    0.000682830810546875,
    -0.1044921875,
    0.0673828125,
    -0.00010395050048828125,
    0.03564453125,
    -0.0106201171875,
    0.032958984375,
    -0.03515625,
    -0.09912109375,
    -0.02880859375,
    -0.0108642578125,
    -0.03759765625,
    0.01214599609375,
    0.0245361328125,
    0.078125,
    -0.033935546875,
    0.00347900390625,
    -0.0186767578125,
    -0.00830078125,
    0.0194091796875,
    -0.010986328125,
    0.091796875,
    0.015625,
    0.019775390625,
    -0.036865234375,
    0.0205078125,
    0.07080078125,
    -0.05615234375,
    0.0126953125,
    0.00701904296875,
    0.01324462890625,
    0.04296875,
    -0.07958984375,
    -0.034423828125,
    -0.045166015625,
    -0.009521484375,
    0.01287841796875,
    -0.0194091796875,
    0.04443359375,
    0.0001678466796875,
    0.01104736328125,
    0.0069580078125,
    0.0185546875,
    -0.11279296875,
    0.0054931640625,
    0.00174713134765625,
    -0.003082275390625,
    -0.00122833251953125,
    -0.0155029296875,
    -0.068359375,
    -0.051513671875,
    -0.064453125,
    0.07861328125,
    -0.0262451171875,
    -0.032958984375,
    -0.036376953125,
    0.0257568359375,
    0.0264892578125,
    0.048828125,
    0.0269775390625,
    -0.0264892578125,
    -0.06103515625,
    0.03515625,
    -0.0010223388671875,
    0.0478515625,
    0.04150390625,
    0.019775390625,
    -0.0247802734375,
    -0.020751953125,
    0.0048828125,
    -0.04638671875,
    -0.03662109375,
    0.054931640625,
    -0.000217437744140625,
    -0.0062255859375,
    -0.005035400390625,
    -0.00787353515625,
    0.034423828125,
    -0.01116943359375,
    -0.0751953125,
    -0.0157470703125,
    -0.030517578125,
    0.052490234375,
    -0.0016632080078125,
    -0.01239013671875,
    -0.05908203125,
    -0.0751953125,
    0.0322265625,
    -0.041259765625,
    0.0081787109375,
    -0.0272216796875,
    0.0291748046875,
    0.005096435546875,
    0.02880859375,
    0.04296875,
    -0.0341796875,
    0.0107421875,
    -0.0361328125,
    0.028564453125,
    0.029052734375,
    0.0185546875,
    0.033203125,
    0.00031280517578125,
    0.04296875,
    0.0302734375,
    -0.01104736328125,
    0.0299072265625,
    -0.040283203125,
    0.00738525390625,
    0.034423828125,
    -0.0380859375,
    -0.00982666015625,
    0.005889892578125,
    0.017822265625,
    -0.01275634765625,
    0.0169677734375,
    -0.0361328125,
    -0.0069580078125,
    0.0419921875,
    0.031494140625,
    0.0361328125,
    0.0223388671875,
    0.033935546875,
    -0.04443359375,
    -0.00174713134765625,
    -0.025390625,
    0.02587890625,
    0.029052734375,
    0.02490234375,
    -0.01043701171875,
    -0.013671875,
    -0.006500244140625,
    0.052734375,
    0.051025390625,
    0.0361328125,
    0.0023956298828125,
    -0.015380859375,
    -0.053466796875,
    0.0296630859375,
    -0.04248046875,
    -0.018798828125,
    -0.000896453857421875,
    -0.06396484375,
    -0.02099609375,
    -0.002471923828125,
    0.023681640625,
    0.0179443359375,
    -0.02099609375,
    -0.0294189453125,
    -0.0108642578125,
    0.01513671875,
    -0.0458984375,
    0.041748046875,
    0.04443359375,
    0.05029296875,
    -0.0279541015625,
    -0.0142822265625,
    0.0233154296875,
    0.0556640625,
    0.0791015625,
    -0.023681640625,
    0.0262451171875,
    0.00634765625,
    0.07470703125,
    -0.007568359375,
    0.03076171875,
    -0.05126953125,
    0.03125,
    0.031982421875,
    -0.004150390625,
    -0.0152587890625,
    0.0296630859375,
    0.033203125,
    -0.01177978515625,
    0.0220947265625,
    -0.0263671875,
    -0.01116943359375,
    -0.0260009765625,
    0.0284423828125,
    0.031494140625,
    -0.05810546875,
    -0.00457763671875,
    -0.018798828125,
    -0.01092529296875,
    0.00421142578125,
    -0.051513671875,
    0.01263427734375,
    -0.0040283203125,
    -0.0361328125,
    0.0146484375,
    -0.018798828125,
    0.0111083984375,
    -0.0390625,
    -0.08056640625,
    -0.013427734375,
    0.043212890625,
    -0.031005859375,
    0.01104736328125,
    -0.050048828125,
    -0.0306396484375,
    -0.0093994140625,
    -0.028076171875,
    -0.0252685546875,
    0.0220947265625,
    -0.01611328125,
    -0.005706787109375,
    0.0191650390625,
    -0.0184326171875,
    0.00238037109375,
    -0.034912109375,
    -0.0791015625,
    -0.0169677734375,
    -0.07177734375,
    -0.0380859375,
    0.0277099609375,
    0.03662109375,
    0.032470703125,
    -0.0498046875,
    0.0093994140625,
    0.01422119140625,
    -0.0296630859375,
    -0.09765625,
    0.0001468658447265625,
    0.0235595703125,
    -0.004425048828125,
    -0.041748046875,
    -0.0029754638671875,
    0.02294921875,
    0.0247802734375,
    -0.01422119140625,
    0.00738525390625,
    -0.005096435546875,
    0.00506591796875,
    -0.025390625,
    -0.015625,
    -0.005706787109375,
    0.030517578125,
    -0.06494140625,
    0.004150390625,
    0.0830078125,
    0.034423828125,
    -0.042724609375,
    0.0341796875,
    0.0390625,
    0.037841796875,
    0.0196533203125,
    -0.0120849609375,
    -0.017822265625,
    -0.0400390625,
    -0.060546875,
    0.01068115234375,
    -0.0306396484375,
    -0.000011682510375976562,
    -0.0274658203125,
    0.03515625,
    -0.003662109375,
    0.0089111328125,
    0.01177978515625,
    0.024658203125,
    -0.0003662109375,
    -0.006744384765625,
    0.03515625,
    0.0228271484375,
    0.0184326171875,
    0.0031890869140625,
    -0.0128173828125,
    -0.0615234375,
    0.020263671875,
    -0.0216064453125,
    -0.01397705078125,
    -0.003021240234375,
    -0.0223388671875,
    0.02294921875,
    0.0030059814453125,
    0.015869140625,
    -0.01226806640625,
    -0.0233154296875,
    -0.05078125,
    -0.01165771484375,
    0.03466796875,
    0.0245361328125,
    0.015869140625,
    -0.0205078125,
    0.042236328125,
    -0.0517578125,
    -0.00787353515625,
    0.04833984375,
    0.0264892578125,
    -0.038330078125,
    0.015380859375,
    0.0194091796875,
    0.025146484375,
    -0.0123291015625,
    0.0017242431640625,
    -0.005401611328125,
    -0.019775390625,
    0.0191650390625,
    0.01080322265625,
    0.010986328125,
    0.0004100799560546875,
    -0.04052734375,
    0.0111083984375,
    0.046142578125,
    -0.032470703125,
    0.08203125,
    -0.041015625,
    -0.005035400390625,
    0.0208740234375,
    -0.00084686279296875,
    0.006683349609375,
    -0.00072479248046875,
    -0.036376953125,
    0.0101318359375,
    0.00058746337890625,
    0.000186920166015625,
    -0.01165771484375,
    0.0240478515625,
    0.046142578125,
    -0.007659912109375,
    0.047119140625,
    0.01141357421875,
    0.015869140625,
    -0.0177001953125,
    0.03759765625,
    0.0126953125,
    0.0390625,
    -0.0147705078125,
    0.060546875,
    -0.05615234375,
    -0.0206298828125,
    0.003021240234375,
    -0.0274658203125,
    0.021728515625,
    0.04736328125,
    0.01165771484375,
    -0.043212890625,
    -0.0022735595703125,
    0.031494140625,
    -0.0164794921875,
    0.01165771484375,
    0.025146484375,
    0.01287841796875,
    0.009521484375,
    0.025146484375,
    -0.056640625,
    0.036376953125,
    0.01190185546875,
    0.04638671875,
    -0.0023040771484375,
    0.004180908203125,
    -0.00592041015625,
    -0.030517578125,
    0.0020599365234375,
    -0.043701171875,
    0.0164794921875,
    -0.018310546875,
    -0.0189208984375,
    -0.00054168701171875,
    0.036865234375,
    -0.0185546875,
    0.0172119140625,
    0.01251220703125,
    0.0135498046875,
    0.033447265625,
    -0.0277099609375,
    0.0128173828125,
    -0.0089111328125,
    -0.0166015625,
    -0.035888671875,
    -0.0306396484375,
    0.03564453125,
    -0.00238037109375,
    -0.0086669921875,
    0.0142822265625,
    0.00250244140625,
    -0.0103759765625,
    0.0184326171875,
    -0.0157470703125,
    -0.032470703125,
    0.00118255615234375,
    0.0126953125,
    0.0264892578125,
    0.0189208984375,
    0.044921875,
    -0.023193359375,
    -0.006011962890625,
    0.04296875,
    0.02685546875,
    -0.056640625,
    -0.01904296875,
    0.005157470703125,
    -0.03271484375,
    0.06640625,
    -0.06640625,
    -0.007232666015625,
    0.016357421875,
    -0.0029144287109375,
    0.01483154296875,
    0.0281982421875,
    -0.015869140625,
    0.03173828125,
    0.0306396484375,
    -0.00421142578125,
    0.04931640625,
    -0.0269775390625,
    0.0556640625,
    0.050537109375,
    0.005157470703125,
    0.039306640625,
    0.0291748046875,
    -0.019287109375,
    0.0184326171875,
    0.0250244140625,
    0.037109375,
    -0.052001953125,
    -0.03759765625,
    -0.00909423828125,
    -0.02685546875,
    -0.023193359375,
    0.0130615234375,
    -0.004638671875,
    -0.013671875,
    -0.009521484375,
    0.0084228515625,
    0.03662109375,
    0.0206298828125,
    -0.035400390625,
    0.0250244140625,
    -0.0029449462890625,
    -0.006744384765625,
    0.00750732421875,
    0.033447265625,
    0.01470947265625,
    -0.0086669921875,
    0.0079345703125,
    0.0238037109375,
    0.015380859375,
    -0.017822265625,
    0.005950927734375,
    -0.031005859375,
    -0.0517578125,
    -0.06640625,
    -0.0137939453125,
    -0.0245361328125,
    0.0030364990234375,
    -0.01708984375,
    -0.00823974609375,
    0.00189208984375,
    -0.006744384765625,
    0.031005859375,
    0.006072998046875,
    0.031982421875,
    0.0054931640625,
    0.005859375,
    -0.0169677734375,
    -0.0015411376953125,
    0.0015869140625,
    0.0216064453125,
    -0.0068359375,
    -0.031494140625,
    0.0257568359375,
    0.000270843505859375,
    0.004791259765625,
    0.020263671875,
    -0.043701171875,
    0.0167236328125,
    -0.0008087158203125,
    -0.01019287109375,
    0.011962890625,
    0.052978515625,
    -0.0272216796875,
    0.0242919921875,
    0.02197265625,
    0.0186767578125,
    -0.0257568359375,
    0.0018463134765625,
    -0.00118255615234375,
    -0.01141357421875,
    -0.031005859375,
    -0.0164794921875,
    0.01043701171875,
    -0.0052490234375,
    -0.0302734375,
    -0.02783203125,
    -0.044921875,
    -0.03076171875,
    -0.0157470703125,
    0.00592041015625,
    -0.00156402587890625,
    0.02880859375,
    0.05322265625,
    0.004913330078125,
    -0.00775146484375,
    -0.01507568359375,
    0.00506591796875,
    -0.039794921875,
    -0.0255126953125,
    0.00531005859375,
    -0.03173828125,
    -0.06982421875,
    0.03076171875,
    0.0218505859375,
    -0.01068115234375,
    0.00634765625,
    -0.07373046875,
    -0.0091552734375,
    -0.00787353515625,
    0.00628662109375,
    0.01031494140625,
    0.01104736328125,
    0.0084228515625,
    0.00994873046875,
    -0.00830078125,
    -0.006561279296875,
    0.004150390625,
    -0.012451171875,
    0.0023193359375,
    0.00640869140625,
    0.03369140625,
    0.002685546875,
    -0.002410888671875,
    -0.0159912109375,
    -0.040771484375,
    -0.0255126953125,
    0.033447265625,
    -0.031005859375,
    0.006988525390625,
    0.01397705078125,
    -0.059814453125,
    -0.02734375,
    0.01806640625,
    0.0181884765625,
    -0.0047607421875,
    -0.022216796875,
    0.0086669921875,
    0.044189453125,
    0.00494384765625,
    -0.04345703125,
    -0.044921875,
    0.0103759765625,
    0.0033416748046875,
    -0.045654296875,
    0.00244140625,
    -0.009521484375,
    -0.01104736328125,
    -0.006439208984375,
    0.04931640625,
    -0.00118255615234375,
    0.01336669921875,
    -0.007354736328125,
    -0.026611328125,
    0.00946044921875,
    -0.00146484375,
    0.0203857421875,
    0.018798828125,
    0.04443359375,
    0.0072021484375,
    0.007110595703125,
    -0.0181884765625,
    -0.01806640625,
    0.0157470703125,
    -0.0252685546875,
    -0.0002765655517578125,
    0.0159912109375,
    0.0242919921875,
    0.0262451171875,
    0.00135040283203125,
    0.031494140625,
    0.059326171875,
    -0.0054931640625,
    0.0025177001953125,
    -0.011962890625,
    0.05908203125,
    -0.005859375,
    -0.0185546875,
    0.0166015625,
    -0.0032196044921875,
    0.0419921875,
    -0.0078125,
    0.0247802734375,
    -0.0306396484375,
    0.0218505859375,
    -0.015869140625,
    -0.0033111572265625,
    0.0037384033203125,
    -0.0016326904296875,
    -0.03759765625,
    0.0205078125,
    -0.01123046875,
    -0.00836181640625,
    -0.028076171875,
    -0.01708984375,
    0.026123046875,
    -0.004180908203125,
    -0.001617431640625,
    -0.0033721923828125,
    -0.0216064453125,
    -0.0260009765625,
    0.0294189453125,
    -0.047119140625,
    -0.04638671875,
    0.0233154296875,
    -0.0223388671875,
    0.03271484375,
    0.004913330078125,
    -0.033203125,
    -0.00188446044921875,
    0.00836181640625,
    0.04052734375,
    -0.0177001953125,
    0.03125,
    -0.0244140625,
    -0.01153564453125,
    0.00616455078125,
    -0.033935546875,
    -0.0030059814453125,
    0.0140380859375,
    -0.0128173828125,
    0.0155029296875,
    0.0274658203125,
    -0.035888671875,
    -0.001220703125,
    0.013671875,
    -0.0255126953125,
    0.01171875,
    -0.002227783203125,
    -0.0147705078125,
    -0.033447265625,
    0.01409912109375,
    -0.0294189453125,
    0.02783203125,
    -0.00634765625,
    -0.01123046875,
    0.04296875,
    0.0274658203125,
    0.019287109375,
    -0.03369140625,
    0.0040283203125,
    0.023193359375,
    -0.0047607421875,
    -0.0093994140625,
    -0.054931640625,
    0.00628662109375,
    0.042236328125,
    0.01092529296875,
    0.01031494140625,
    0.025146484375,
    -0.035888671875,
    -0.00122833251953125,
    -0.0019378662109375,
    0.0260009765625,
    -0.00714111328125,
    0.0004787445068359375,
    0.005462646484375,
    0.0021209716796875,
    0.031982421875,
    0.007049560546875,
    0.0299072265625,
    -0.027099609375,
    0.037353515625,
    -0.0277099609375,
    0.01116943359375,
    0.0166015625,
    -0.00665283203125,
    -0.0283203125,
    -0.0303955078125,
    0.034912109375,
    0.0654296875,
    0.043701171875,
    -0.0093994140625,
    -0.01361083984375,
    -0.020751953125,
    -0.0040283203125,
    -0.017578125,
    -0.007537841796875,
    0.0003299713134765625,
    -0.0172119140625,
    -0.0050048828125,
    0.01416015625,
    -0.0022125244140625,
    -0.035400390625,
    -0.0101318359375,
    0.01507568359375,
    -0.0179443359375,
    0.0810546875,
    0.01611328125,
    -0.01373291015625,
    0.0203857421875,
    -0.0098876953125,
    0.0167236328125,
    -0.0166015625,
    0.0030364990234375,
    0.020751953125,
    0.010009765625,
    -0.00994873046875,
    -0.0162353515625,
    -0.0091552734375,
    -0.0028076171875,
    0.02001953125,
    -0.0167236328125,
    -0.03369140625,
    -0.041259765625,
    0.030029296875,
    0.022705078125,
    0.0400390625,
    -0.01904296875,
    0.03125,
    0.026611328125,
    -0.0019378662109375,
    -0.00396728515625,
    0.01531982421875,
    0.005859375,
    0.00830078125,
    -0.01513671875,
    -0.0225830078125,
    0.00872802734375,
    0.004486083984375,
    -0.0289306640625,
    0.0054931640625,
    -0.009521484375,
    -0.0029144287109375,
    -0.0230712890625,
    -0.028564453125,
    -0.024658203125,
    0.0260009765625,
    0.018310546875,
    -0.000701904296875,
    0.019287109375,
    0.00439453125,
    -0.044921875,
    -0.01171875,
    0.0012359619140625,
    -0.018310546875,
    -0.0225830078125,
    0.0439453125,
    -0.0177001953125,
    0.0283203125,
    -0.033203125,
    0.0014495849609375,
    0.046630859375,
    0.0167236328125,
    0.02734375,
    -0.01007080078125,
    -0.01519775390625,
    0.01190185546875,
    0.00799560546875,
    0.031494140625,
    -0.0025787353515625,
    -0.0172119140625,
    0.0184326171875,
    -0.0196533203125,
    0.031494140625,
    0.02197265625,
    0.0213623046875,
    -0.004638671875,
    0.0184326171875,
    -0.034912109375,
    -0.0120849609375,
    -0.015869140625,
    -0.0089111328125,
    0.01904296875,
    -0.004669189453125,
    0.017822265625,
    -0.03466796875,
    -0.003204345703125,
    -0.043701171875,
    0.050048828125,
    0.0015106201171875,
    0.022216796875,
    -0.003570556640625,
    0.013427734375,
    0.008544921875,
    0.015380859375,
    -0.0546875,
    0.0216064453125,
    -0.007415771484375,
    -0.012451171875,
    -0.03564453125,
    0.024169921875,
    -0.0091552734375,
    0.00775146484375,
    0.002471923828125,
    -0.01226806640625,
    -0.0189208984375,
    0.0303955078125,
    -0.0264892578125,
    0.044189453125,
    -0.030029296875,
    -0.0000762939453125,
    0.0103759765625,
    -0.011474609375,
    0.01165771484375,
    -0.0123291015625,
    0.013916015625,
    -0.01275634765625,
    -0.0167236328125,
    -0.003021240234375,
    0.01409912109375,
    -0.0106201171875,
    -0.0014801025390625,
    -0.004486083984375,
    -0.0166015625,
    -0.01239013671875,
    -0.044189453125,
    -0.009033203125,
    -0.0016632080078125,
    0.0234375,
    -0.04541015625,
    0.006134033203125,
    -0.0185546875,
    0.0147705078125,
    0.019775390625,
    0.0284423828125,
    0.0673828125,
    -0.004791259765625,
    0.01171875,
    -0.030517578125,
    -0.007476806640625,
    -0.004913330078125,
    -0.0277099609375,
    0.007080078125,
    -0.01171875,
    0.007476806640625,
    -0.000728607177734375,
    -0.00787353515625,
    0.01263427734375,
    0.0234375,
    0.0235595703125,
    -0.0244140625,
    -0.0419921875,
    -0.001129150390625,
    -0.010498046875,
    -0.0152587890625,
    -0.0208740234375,
    -0.01904296875,
    -0.037109375,
    -0.00909423828125,
    -0.0269775390625,
    -0.025390625,
    0.005767822265625,
    0.005096435546875,
    -0.0281982421875,
    0.0228271484375,
    -0.0272216796875,
    0.0029296875,
    -0.013427734375,
    0.006103515625,
    0.032958984375,
    -0.013916015625,
    0.0137939453125,
    -0.03125,
    0.04638671875,
    -0.0048828125,
    0.00994873046875,
    0.0145263671875,
    -0.042236328125,
    -0.004974365234375,
    0.0174560546875,
    0.034912109375,
    -0.03125,
    0.00762939453125,
    -0.002349853515625,
    0.0045166015625,
    0.006561279296875,
    -0.0693359375,
    -0.0012359619140625,
    0.0225830078125,
    0.00170135498046875,
    -0.003692626953125,
    0.028076171875,
    0.0018768310546875,
    -0.0118408203125,
    0.0262451171875,
    0.057861328125,
    -0.01611328125,
    0.00921630859375,
    -0.0167236328125,
    -0.019287109375,
    0.01226806640625,
    0.00848388671875,
    0.040771484375,
    0.0111083984375,
    0.0252685546875,
    -0.02294921875,
    0.0302734375,
    0.033447265625,
    -0.00010204315185546875,
    0.041748046875,
    -0.018798828125,
    0.016357421875,
    -0.0322265625,
    -0.01031494140625,
    0.01239013671875,
    -0.032958984375,
    -0.000286102294921875,
    -0.00433349609375,
    0.01251220703125,
    0.018798828125,
    0.0263671875,
    -0.03857421875,
    0.00162506103515625,
    -0.0002498626708984375,
    0.00689697265625,
    0.001678466796875,
    0.00994873046875,
    -0.0033721923828125,
    0.01953125,
    -0.0118408203125,
    0.0390625,
    -0.0234375,
    0.033203125,
    0.0179443359375,
    -0.0284423828125,
    -0.019775390625,
    0.031494140625,
    0.0135498046875,
    -0.004547119140625,
    0.00022411346435546875,
    -0.006591796875,
    0.004638671875,
    0.0262451171875,
    -0.0005035400390625,
    0.0034332275390625,
    0.0283203125,
    -0.018798828125,
    0.01220703125,
    0.03466796875,
    -0.00225830078125,
    0.005157470703125,
    0.048828125,
    0.0025634765625,
    0.0034332275390625,
    0.027099609375,
    -0.018310546875,
    -0.00323486328125,
    0.0072021484375,
    -0.0172119140625,
    0.023681640625,
    0.01116943359375,
    0.00823974609375,
    -0.01171875,
    -0.004608154296875,
    -0.026123046875,
    0.0016632080078125,
    -0.0234375,
    0.01446533203125,
    -0.006439208984375,
    -0.03271484375,
    -0.0030975341796875,
    0.0059814453125,
    0.002410888671875,
    0.040771484375,
    0.036376953125,
    0.0152587890625,
    0.0220947265625,
    0.01348876953125,
    0.000614166259765625,
    0.014892578125,
    -0.01165771484375,
    -0.03515625,
    -0.0037384033203125,
    -0.022705078125,
    0.0157470703125,
    0.000606536865234375,
    -0.012451171875
  ],
  "created": "2025-06-12T05:14:14.234978",
  "count": 27
}