{
  "id": "section_3_1",
  "text": "III.1 VALUES Respect, protection and promotion of human rights and fundamental freedoms and human dignity 13. The inviolable and inherent dignity of every human constitutes the foundation for the universal, indivisible, inalienable, interdependent and interrelated system of human rights and fundamental freedoms. Therefore, respect, protection and promotion of human dignity and rights as established by international law, including international human rights law, is essential throughout the life cycle of AI systems. Human dignity relates to the recognition of the intrinsic and equal worth of each individual human being, regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds. 14. No human being or human community should be harmed or subordinated, whether physically, economically, socially, politically, culturally or mentally during any phase of the life cycle of AI systems. Throughout the life cycle of AI systems, the quality of life of human beings should be enhanced, while the definition of 'quality of life' should be left open to individuals or groups, as long as there is no violation or abuse of human rights and fundamental freedoms, or the dignity of humans in terms of this definition. 15. Persons may interact with AI systems throughout their life cycle and receive assistance from them, such as care for vulnerable people or people in vulnerable situations, including but not limited to children, older persons, persons with disabilities or the ill. Within such interactions, persons should never be objectified, nor should their dignity be otherwise undermined, or human rights and fundamental freedoms violated or abused. 16. Human rights and fundamental freedoms must be respected, protected and promoted throughout the life cycle of AI systems. Governments, private sector, civil society, international organizations, technical communities and academia must respect human rights instruments and frameworks in their interventions in the processes surrounding the life cycle of AI systems. New technologies need to provide new means to advocate, defend and exercise human rights and not to infringe them. Environmental and ecosystem flourishing 17. Environmental and ecosystem flourishing should be recognized, protected and promoted through the life cycle of AI systems. Furthermore, environment and ecosystems are the existential necessity for humanity and other living beings to be able to enjoy the benefits of advances in AI. 18. All actors involved in the life cycle of AI systems must comply with applicable international law and domestic legislation, standards and practices, such as precaution, designed for environmental and ecosystem protection and restoration, and sustainable development. They should reduce the environmental impact of AI systems, including but not limited to its carbon footprint, to ensure the minimization of climate change and environmental risk factors, and prevent the unsustainable exploitation, use and transformation of natural resources contributing to the deterioration of the environment and the degradation of ecosystems. Ensuring diversity and inclusiveness 19. Respect, protection and promotion of diversity and inclusiveness should be ensured throughout the life cycle of AI systems, consistent with international law, including human rights law. This may be done by promoting active participation of all individuals or groups regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds. 20. The scope of lifestyle choices, beliefs, opinions, expressions or personal experiences, including the optional use of AI systems and the co-design of these architectures should not be restricted during any phase of the life cycle of AI systems. 21. Furthermore, efforts, including international cooperation, should be made to overcome, and never take advantage of, the lack of necessary technological infrastructure, education and skills, as well as legal frameworks, particularly in LMICs, LDCs, LLDCs and SIDS, affecting communities. Living in peaceful, just and interconnected societies 22. AI actors should play a participative and enabling role to ensure peaceful and just societies, which is based on an interconnected future for the benefit of all, consistent with human rights and fundamental freedoms. The value of living in peaceful and just societies points to the potential of AI systems to contribute throughout their life cycle to the interconnectedness of all living creatures with each other and with the natural environment. 23. The notion of humans being interconnected is based on the knowledge that every human belongs to a greater whole, which thrives when all its constituent parts are enabled to thrive. Living in peaceful, just and interconnected societies requires an organic, immediate, uncalculated bond of solidarity, characterized by a permanent search for peaceful relations, tending towards care for others and the natural environment in the broadest sense of the term. 24. This value demands that peace, inclusiveness and justice, equity and interconnectedness should be promoted throughout the life cycle of AI systems, in so far as the processes of the life cycle of AI systems should not segregate, objectify or undermine freedom and autonomous decision-making as well as the safety of human beings and communities, divide and turn individuals and groups against each other, or threaten the coexistence between humans, other living beings and the natural environment. III.2 PRINCIPLES Proportionality and Do No Harm 25. It should be recognized that AI technologies do not necessarily, per se, ensure human and environmental and ecosystem flourishing. Furthermore, none of the processes related to the AI system life cycle shall exceed what is necessary to achieve legitimate aims or objectives and should be appropriate to the context. In the event of possible occurrence of any harm to human beings, human rights and fundamental freedoms, communities and society at large or the environment and ecosystems, the implementation of procedures for risk assessment and the adoption of measures in order to preclude the occurrence of such harm should be ensured. 26. The choice to use AI systems and which AI method to use should be justified in the following ways: (a) the AI method chosen should be appropriate and proportional to achieve a given legitimate aim; (b) the AI method chosen should not infringe upon the foundational values captured in this document, in particular, its use must not violate or abuse human rights; and (c) the AI method should be appropriate to the context and should be based on rigorous scientific foundations. In scenarios where decisions are understood to have an impact that is irreversible or difficult to reverse or may involve life and death decisions, final human determination should apply. In particular, AI systems should not be used for social scoring or mass surveillance purposes. Safety and security 27. Unwanted harms (safety risks), as well as vulnerabilities to attack (security risks) should be avoided and should be addressed, prevented and eliminated throughout the life cycle of AI systems to ensure human, environmental and ecosystem safety and security. Safe and secure AI will be enabled by the development of sustainable, privacy-protective data access frameworks that foster better training and validation of AI models utilizing quality data. Fairness and non-discrimination 28. AI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance with international law. This implies an inclusive approach to ensuring that the benefits of AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups, cultural systems, different language groups, persons with disabilities, girls and women, and disadvantaged, marginalized and vulnerable people or people in vulnerable situations. Member States should work to promote inclusive access for all, including local communities, to AI systems with locally relevant content and services, and with respect for multilingualism and cultural diversity. Member States should work to tackle digital divides and ensure inclusive access to and participation in the development of AI. At the national level, Member States should promote equity between rural and urban areas, and among all persons regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds, in terms of access to and participation in the AI system life cycle. At the international level, the most technologically advanced countries have a responsibility of solidarity with the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life cycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research and socio-economic and political stability. 29. AI actors should make all reasonable efforts to minimize and avoid reinforcing or perpetuating discriminatory or biased applications and outcomes throughout the life cycle of the AI system to ensure fairness of such systems. Effective remedy should be available against discrimination and biased algorithmic determination. 30. Furthermore, digital and knowledge divides within and between countries need to be addressed throughout an AI system life cycle, including in terms of access and quality of access to technology and data, in accordance with relevant national, regional and international legal frameworks, as well as in terms of connectivity, knowledge and skills and meaningful participation of the affected communities, such that every person is treated equitably. Sustainability 31. The development of sustainable societies relies on the achievement of a complex set of objectives on a continuum of human, social, cultural, economic and environmental dimensions. The advent of AI technologies can either benefit sustainability objectives or hinder their realization, depending on how they are applied across countries with varying levels of development. The continuous assessment of the human, social, cultural, economic and environmental impact of AI technologies should therefore be carried out with full cognizance of the implications of AI technologies for sustainability as a set of constantly evolving goals across a range of dimensions, such as currently identified in the Sustainable Development Goals (SDGs) of the United Nations. Right to Privacy, and Data Protection 32. Privacy, a right essential to the protection of human dignity, human autonomy and human agency, must be respected, protected and promoted throughout the life cycle of AI systems. It is important that data for AI systems be collected, used, shared, archived and deleted in ways that are consistent with international law and in line with the values and principles set forth in this Recommendation, while respecting relevant national, regional and international legal frameworks. 33. Adequate data protection frameworks and governance mechanisms should be established in a multi-stakeholder approach at the national or international level, protected by judicial systems, and ensured throughout the life cycle of AI systems. Data protection frameworks and any related mechanisms should take reference from international data protection principles and standards concerning the collection, use and disclosure of personal data and exercise of their rights by data subjects while ensuring a legitimate aim and a valid legal basis for the processing of personal data, including informed consent. 34. Algorithmic systems require adequate privacy impact assessments, which also include societal and ethical considerations of their use and an innovative use of the privacy by design approach. AI actors need to ensure that they are accountable for the design and implementation of AI systems in such a way as to ensure that personal information is protected throughout the life cycle of the AI system. Human oversight and determination 35. Member States should ensure that it is always possible to attribute ethical and legal responsibility for any stage of the life cycle of AI systems, as well as in cases of remedy related to AI systems, to physical persons or to existing legal entities. Human oversight refers thus not only to individual human oversight, but to inclusive public oversight, as appropriate. 36. It may be the case that sometimes humans would choose to rely on AI systems for reasons of efficacy, but the decision to cede control in limited contexts remains that of humans, as humans can resort to AI systems in decision-making and acting, but an AI system can never replace ultimate human responsibility and accountability. As a rule, life and death decisions should not be ceded to AI systems. Transparency and explainability 37. The transparency and explainability of AI systems are often essential preconditions to ensure the respect, protection and promotion of human rights, fundamental freedoms and ethical principles. Transparency is necessary for relevant national and international liability regimes to work effectively. A lack of transparency could also undermine the possibility of effectively challenging decisions based on outcomes produced by AI systems and may thereby infringe the right to a fair trial and effective remedy, and limits the areas in which these systems can be legally used. 38. While efforts need to be made to increase transparency and explainability of AI systems, including those with extra-territorial impact, throughout their life cycle to support democratic governance, the level of transparency and explainability should always be appropriate to the context and impact, as there may be a need to balance between transparency and explainability and other principles such as privacy, safety and security. People should be fully informed when a decision is informed by or is made on the basis of AI algorithms, including when it affects their safety or human rights, and in those circumstances should have the opportunity to request explanatory information from the relevant AI actor or public sector institutions. In addition, individuals should be able to access the reasons for a decision affecting their rights and freedoms, and have the option of making submissions to a designated staff member of the private sector company or public sector institution able to review and correct the decision. AI actors should inform users when a product or service is provided directly or with the assistance of AI systems in a proper and timely manner. 39. From a socio-technical lens, greater transparency contributes to more peaceful, just, democratic and inclusive societies. It allows for public scrutiny that can decrease corruption and discrimination, and can also help detect and prevent negative impacts on human rights. Transparency aims at providing appropriate information to the respective addressees to enable their understanding and foster trust. Specific to the AI system, transparency can enable people to understand how each stage of an AI system is put in place, appropriate to the context and sensitivity of the AI system. It may also include insight into factors that affect a specific prediction or decision, and whether or not appropriate assurances (such as safety or fairness measures) are in place. In cases of serious threats of adverse human rights impacts, transparency may also require the sharing of code or datasets. 40. Explainability refers to making intelligible and providing insight into the outcome of AI systems. The explainability of AI systems also refers to the understandability of the input, output and the functioning of each algorithmic building block and how it contributes to the outcome of the systems. Thus, explainability is closely related to transparency, as outcomes and sub-processes leading to outcomes should aim to be understandable and traceable, appropriate to the context. AI actors should commit to ensuring that the algorithms developed are explainable. In the case of AI applications that impact the end user in a way that is not temporary, easily reversible or otherwise low risk, it should be ensured that the meaningful explanation is provided with any decision that resulted in the action taken in order for the outcome to be considered transparent. 41. Transparency and explainability relate closely to adequate responsibility and accountability measures, as well as to the trustworthiness of AI systems. Responsibility and accountability 42. AI actors and Member States should respect, protect and promote human rights and fundamental freedoms, and should also promote the protection of the environment and ecosystems, assuming their respective ethical and legal responsibility, in accordance with national and international law, in particular Member States' human rights obligations, and ethical guidance throughout the life cycle of AI systems, including with respect to AI actors within their effective territory and control. The ethical responsibility and liability for the decisions and actions based in any way on an AI system should always ultimately be attributable to AI actors corresponding to their role in the life cycle of the AI system. 43. Appropriate oversight, impact assessment, audit and due diligence mechanisms, including whistle-blowers' protection, should be developed to ensure accountability for AI systems and their impact throughout their life cycle. Both technical and institutional designs should ensure auditability and traceability of (the working of) AI systems in particular to address any conflicts with human rights norms and standards and threats to environmental and ecosystem well-being. Awareness and literacy 44. Public awareness and understanding of AI technologies and the value of data should be promoted through open and accessible education, civic engagement, digital skills and AI ethics training, media and information literacy and training led jointly by governments, intergovernmental organizations, civil society, academia, the media, community leaders and the private sector, and considering the existing linguistic, social and cultural diversity, to ensure effective public participation so that all members of society can take informed decisions about their use of AI systems and be protected from undue influence. 45. Learning about the impact of AI systems should include learning about, through and for human rights and fundamental freedoms, meaning that the approach and understanding of AI systems should be grounded by their impact on human rights and access to rights, as well as on the environment and ecosystems. Multi-stakeholder and adaptive governance and collaboration 46. International law and national sovereignty must be respected in the use of data. That means that States, complying with international law, can regulate the data generated within or passing through their territories, and take measures towards effective regulation of data, including data protection, based on respect for the right to privacy in accordance with international law and other human rights norms and standards. Participation of different stakeholders throughout the AI system life cycle is necessary for inclusive approaches to AI governance, enabling the benefits to be shared by all, and to contribute to sustainable development. Stakeholders include but are not limited to governments, intergovernmental organizations, the technical community, civil society, researchers and academia, media, education, policy-makers, private sector companies, human rights institutions and equality bodies, anti-discrimination monitoring bodies, and groups for youth and children. The adoption of open standards and interoperability to facilitate collaboration should be in place. Measures should be adopted to take into account shifts in technologies, the emergence of new groups of stakeholders, and to allow for meaningful participation by marginalized groups, communities and individuals and, where relevant, in the case of Indigenous Peoples, respect for the self-governance of their data.",
  "embedding": [
    0.177734375,
    -0.1728515625,
    0.1435546875,
    0.01019287109375,
    0.01611328125,
    -0.08544921875,
    0.010009765625,
    0.02099609375,
    -0.008544921875,
    -0.006439208984375,
    0.017333984375,
    0.10498046875,
    0.009033203125,
    -0.0498046875,
    0.09130859375,
    -0.028076171875,
    -0.02783203125,
    0.047119140625,
    -0.061279296875,
    -0.103515625,
    0.03515625,
    -0.0791015625,
    0.0654296875,
    0.1328125,
    -0.06396484375,
    0.0703125,
    -0.02490234375,
    0.04296875,
    -0.00970458984375,
    0.00153350830078125,
    0.044921875,
    -0.09033203125,
    0.00750732421875,
    -0.0859375,
    -0.006561279296875,
    0.0169677734375,
    0.06982421875,
    -0.01025390625,
    -0.020263671875,
    -0.040771484375,
    -0.028076171875,
    -0.044189453125,
    0.046875,
    -0.05908203125,
    0.08154296875,
    0.057373046875,
    0.0498046875,
    0.0218505859375,
    -0.07080078125,
    -0.03173828125,
    0.115234375,
    0.058349609375,
    -0.050048828125,
    0.056396484375,
    0.005767822265625,
    0.039794921875,
    0.0206298828125,
    -0.0211181640625,
    -0.0498046875,
    0.0206298828125,
    -0.10498046875,
    0.03369140625,
    -0.0673828125,
    -0.041015625,
    -0.0177001953125,
    0.09912109375,
    -0.0260009765625,
    -0.05224609375,
    0.019775390625,
    -0.01055908203125,
    -0.0283203125,
    0.0302734375,
    -0.02734375,
    0.0223388671875,
    0.005218505859375,
    0.0269775390625,
    -0.029541015625,
    0.07275390625,
    -0.02099609375,
    0.00408935546875,
    0.08349609375,
    0.04052734375,
    0.038818359375,
    -0.0101318359375,
    0.01177978515625,
    0.0537109375,
    -0.0859375,
    0.0213623046875,
    0.006561279296875,
    -0.047119140625,
    -0.00193023681640625,
    -0.0712890625,
    -0.019775390625,
    -0.0361328125,
    0.0654296875,
    -0.00109100341796875,
    -0.04541015625,
    0.025146484375,
    -0.051025390625,
    -0.00738525390625,
    -0.0908203125,
    0.044921875,
    -0.09716796875,
    0.07470703125,
    0.0089111328125,
    0.04345703125,
    -0.022216796875,
    -0.035400390625,
    -0.07421875,
    -0.0093994140625,
    0.010498046875,
    -0.013916015625,
    0.025634765625,
    -0.00135040283203125,
    0.0322265625,
    0.06396484375,
    0.00113677978515625,
    0.0517578125,
    0.0634765625,
    0.00079345703125,
    0.01092529296875,
    -0.017822265625,
    -0.0238037109375,
    0.011474609375,
    0.016357421875,
    -0.03515625,
    -0.053955078125,
    0.0400390625,
    0.00433349609375,
    -0.064453125,
    0.01239013671875,
    0.057861328125,
    -0.05078125,
    -0.0147705078125,
    0.004669189453125,
    0.00421142578125,
    0.0037994384765625,
    -0.034423828125,
    -0.0146484375,
    0.0247802734375,
    0.01531982421875,
    0.01165771484375,
    -0.0546875,
    -0.0106201171875,
    0.01336669921875,
    -0.036376953125,
    -0.025146484375,
    0.000021696090698242188,
    0.01300048828125,
    0.058349609375,
    0.08447265625,
    0.01287841796875,
    0.00921630859375,
    -0.004638671875,
    0.03271484375,
    0.000522613525390625,
    0.02294921875,
    0.0223388671875,
    0.0054931640625,
    0.0023956298828125,
    0.000514984130859375,
    0.03515625,
    0.0084228515625,
    -0.0284423828125,
    -0.052978515625,
    0.023193359375,
    -0.016357421875,
    0.035400390625,
    0.002899169921875,
    -0.01336669921875,
    -0.043212890625,
    0.042724609375,
    0.010986328125,
    -0.0322265625,
    -0.0242919921875,
    0.006927490234375,
    -0.0009918212890625,
    0.08447265625,
    0.0458984375,
    0.07666015625,
    0.013427734375,
    -0.023193359375,
    -0.04150390625,
    0.0361328125,
    -0.07373046875,
    0.01214599609375,
    0.0023956298828125,
    -0.0142822265625,
    0.0220947265625,
    -0.00927734375,
    -0.006317138671875,
    -0.0140380859375,
    0.060791015625,
    0.06298828125,
    -0.031982421875,
    0.011474609375,
    -0.044921875,
    0.00701904296875,
    -0.0286865234375,
    -0.04638671875,
    0.0074462890625,
    -0.0235595703125,
    -0.003936767578125,
    0.0203857421875,
    -0.030029296875,
    0.046142578125,
    -0.00811767578125,
    0.00124359130859375,
    -0.0322265625,
    0.016357421875,
    0.026611328125,
    0.01385498046875,
    0.017578125,
    -0.0123291015625,
    -0.06494140625,
    -0.050048828125,
    0.061767578125,
    0.056884765625,
    0.0225830078125,
    -0.010986328125,
    0.00049591064453125,
    -0.02783203125,
    0.0281982421875,
    -0.014892578125,
    -0.0123291015625,
    -0.00823974609375,
    -0.033203125,
    0.0186767578125,
    -0.01904296875,
    0.051513671875,
    0.0233154296875,
    0.0166015625,
    -0.00897216796875,
    0.0096435546875,
    0.050048828125,
    -0.023681640625,
    -0.03369140625,
    0.045654296875,
    0.07568359375,
    -0.0311279296875,
    -0.052490234375,
    -0.034423828125,
    -0.041259765625,
    0.013671875,
    -0.047119140625,
    -0.006317138671875,
    -0.04052734375,
    -0.0234375,
    -0.05078125,
    -0.0260009765625,
    0.0184326171875,
    -0.0003108978271484375,
    -0.0439453125,
    -0.01544189453125,
    0.02490234375,
    -0.03857421875,
    0.00107574462890625,
    -0.0257568359375,
    -0.033203125,
    0.0186767578125,
    -0.0308837890625,
    -0.03466796875,
    -0.0137939453125,
    -0.007171630859375,
    0.0208740234375,
    0.00274658203125,
    0.00006818771362304688,
    -0.0177001953125,
    0.0048828125,
    -0.029541015625,
    -0.006866455078125,
    -0.01287841796875,
    -0.01519775390625,
    0.061767578125,
    0.008056640625,
    0.0303955078125,
    -0.00860595703125,
    0.017578125,
    0.0185546875,
    -0.027587890625,
    -0.041259765625,
    -0.019287109375,
    0.01300048828125,
    0.016845703125,
    -0.033935546875,
    -0.03369140625,
    -0.0242919921875,
    0.0341796875,
    -0.01251220703125,
    0.01177978515625,
    0.01202392578125,
    -0.0211181640625,
    0.00106048583984375,
    0.01385498046875,
    -0.004791259765625,
    -0.00738525390625,
    -0.083984375,
    0.0040283203125,
    0.04541015625,
    0.0026702880859375,
    -0.0308837890625,
    0.0179443359375,
    0.05126953125,
    0.0289306640625,
    -0.0194091796875,
    0.00058746337890625,
    0.025390625,
    -0.036376953125,
    -0.0240478515625,
    0.005889892578125,
    -0.025146484375,
    -0.033935546875,
    0.0234375,
    0.0240478515625,
    -0.03466796875,
    0.004241943359375,
    -0.0380859375,
    0.0306396484375,
    0.005950927734375,
    0.0020751953125,
    -0.02783203125,
    -0.004669189453125,
    -0.0308837890625,
    0.0308837890625,
    -0.0311279296875,
    -0.054443359375,
    0.0011138916015625,
    -0.036376953125,
    0.0174560546875,
    -0.003143310546875,
    -0.0126953125,
    -0.01019287109375,
    0.01904296875,
    0.052001953125,
    -0.003204345703125,
    -0.0252685546875,
    -0.049560546875,
    -0.005126953125,
    -0.004364013671875,
    -0.004608154296875,
    0.017578125,
    0.01055908203125,
    0.042724609375,
    -0.015869140625,
    0.01031494140625,
    0.0311279296875,
    0.024169921875,
    -0.016845703125,
    0.029296875,
    0.0390625,
    -0.0159912109375,
    -0.0031585693359375,
    -0.0257568359375,
    0.0113525390625,
    0.0037841796875,
    0.0274658203125,
    0.02734375,
    -0.035400390625,
    0.010009765625,
    -0.06689453125,
    -0.01531982421875,
    0.0147705078125,
    -0.00250244140625,
    0.06494140625,
    0.00127410888671875,
    0.00180816650390625,
    0.0712890625,
    -0.00885009765625,
    0.016845703125,
    -0.004119873046875,
    -0.024658203125,
    -0.0283203125,
    -0.046142578125,
    0.00106048583984375,
    -0.0147705078125,
    0.0089111328125,
    -0.00311279296875,
    0.0269775390625,
    0.05224609375,
    -0.0233154296875,
    0.0108642578125,
    -0.0263671875,
    0.000644683837890625,
    0.00506591796875,
    0.010498046875,
    0.00506591796875,
    0.06298828125,
    -0.036865234375,
    0.022216796875,
    0.0174560546875,
    -0.000514984130859375,
    -0.030029296875,
    0.06298828125,
    -0.023681640625,
    -0.05078125,
    0.004791259765625,
    0.03564453125,
    -0.07373046875,
    -0.0089111328125,
    0.0458984375,
    0.043701171875,
    0.0224609375,
    0.0003719329833984375,
    -0.040283203125,
    0.0277099609375,
    0.01025390625,
    0.01513671875,
    -0.019775390625,
    -0.0390625,
    0.000583648681640625,
    -0.045166015625,
    0.053466796875,
    -0.0032196044921875,
    0.0084228515625,
    0.001068115234375,
    -0.047607421875,
    0.0223388671875,
    -0.001556396484375,
    -0.03369140625,
    -0.00933837890625,
    -0.003692626953125,
    0.01806640625,
    -0.005584716796875,
    -0.0020294189453125,
    0.013427734375,
    0.01544189453125,
    -0.0159912109375,
    -0.0380859375,
    0.005218505859375,
    -0.01300048828125,
    -0.03759765625,
    0.008056640625,
    0.0125732421875,
    0.0181884765625,
    0.0191650390625,
    -0.01544189453125,
    0.003021240234375,
    -0.0228271484375,
    -0.01312255859375,
    -0.0228271484375,
    0.015869140625,
    0.044921875,
    0.01458740234375,
    -0.0107421875,
    0.029541015625,
    0.0164794921875,
    0.03369140625,
    -0.07568359375,
    -0.030029296875,
    -0.01373291015625,
    -0.035888671875,
    0.01165771484375,
    -0.046875,
    -0.0128173828125,
    0.01239013671875,
    0.0267333984375,
    0.060791015625,
    0.012451171875,
    0.0234375,
    -0.00482177734375,
    0.0174560546875,
    -0.03515625,
    0.057861328125,
    -0.0262451171875,
    0.07861328125,
    0.00311279296875,
    0.03662109375,
    0.00726318359375,
    0.01336669921875,
    -0.04638671875,
    0.0069580078125,
    0.030029296875,
    0.005645751953125,
    -0.025146484375,
    -0.007568359375,
    0.01611328125,
    -0.01251220703125,
    -0.0228271484375,
    -0.0242919921875,
    0.03515625,
    -0.0164794921875,
    -0.0203857421875,
    0.0308837890625,
    0.0400390625,
    0.01336669921875,
    -0.0137939453125,
    -0.039794921875,
    0.00018310546875,
    0.0205078125,
    0.0245361328125,
    -0.005859375,
    0.002685546875,
    0.0135498046875,
    0.06591796875,
    0.020751953125,
    -0.00286865234375,
    0.06396484375,
    -0.0120849609375,
    -0.0257568359375,
    -0.061279296875,
    -0.058349609375,
    0.00457763671875,
    0.02587890625,
    0.0289306640625,
    -0.00012969970703125,
    -0.028076171875,
    -0.012939453125,
    -0.023193359375,
    0.0150146484375,
    0.00543212890625,
    -0.02490234375,
    0.0186767578125,
    0.002105712890625,
    -0.00142669677734375,
    0.0341796875,
    0.01708984375,
    0.00396728515625,
    -0.006134033203125,
    -0.00469970703125,
    0.005126953125,
    -0.01226806640625,
    -0.01287841796875,
    0.052734375,
    -0.05615234375,
    -0.006591796875,
    0.016845703125,
    0.017822265625,
    -0.026123046875,
    0.00927734375,
    0.0069580078125,
    0.0311279296875,
    0.0012359619140625,
    0.0224609375,
    -0.002044677734375,
    -0.022705078125,
    0.0225830078125,
    -0.0167236328125,
    -0.0291748046875,
    -0.0181884765625,
    0.00701904296875,
    0.007232666015625,
    -0.0205078125,
    -0.006134033203125,
    -0.0517578125,
    -0.0517578125,
    0.001220703125,
    -0.0167236328125,
    0.031494140625,
    0.031494140625,
    0.005950927734375,
    -0.0020751953125,
    0.004547119140625,
    0.006439208984375,
    0.0101318359375,
    -0.007293701171875,
    -0.05859375,
    0.005767822265625,
    -0.0308837890625,
    0.0033416748046875,
    -0.0081787109375,
    0.013671875,
    -0.010986328125,
    0.007568359375,
    -0.02734375,
    -0.0242919921875,
    -0.012939453125,
    -0.0137939453125,
    0.01904296875,
    0.01080322265625,
    0.0186767578125,
    -0.0234375,
    -0.016357421875,
    -0.02197265625,
    0.019775390625,
    0.03857421875,
    -0.0062255859375,
    0.0322265625,
    0.022216796875,
    0.032958984375,
    0.0257568359375,
    -0.0289306640625,
    -0.014892578125,
    -0.024658203125,
    0.043212890625,
    0.0140380859375,
    0.020751953125,
    -0.01904296875,
    0.0024261474609375,
    0.01708984375,
    -0.03173828125,
    0.04296875,
    0.012451171875,
    0.0216064453125,
    0.0023651123046875,
    0.021484375,
    -0.00124359130859375,
    -0.01373291015625,
    -0.052734375,
    -0.0162353515625,
    0.0286865234375,
    -0.07861328125,
    -0.004974365234375,
    0.01068115234375,
    0.000946044921875,
    0.007720947265625,
    0.042236328125,
    0.01080322265625,
    -0.01544189453125,
    -0.049072265625,
    -0.0186767578125,
    0.0017547607421875,
    0.028076171875,
    -0.0211181640625,
    -0.031494140625,
    0.029541015625,
    0.0311279296875,
    0.005706787109375,
    -0.0341796875,
    -0.0027923583984375,
    0.0079345703125,
    0.031494140625,
    -0.01385498046875,
    0.03662109375,
    0.00396728515625,
    0.00347900390625,
    -0.03271484375,
    0.060791015625,
    0.043701171875,
    -0.000797271728515625,
    0.0238037109375,
    0.000492095947265625,
    0.0380859375,
    0.0260009765625,
    0.004486083984375,
    0.01287841796875,
    0.0306396484375,
    0.00927734375,
    -0.0177001953125,
    0.0380859375,
    0.0211181640625,
    0.01806640625,
    -0.004730224609375,
    -0.01226806640625,
    0.0250244140625,
    -0.0150146484375,
    -0.044921875,
    0.02734375,
    -0.016845703125,
    -0.0004482269287109375,
    -0.0291748046875,
    -0.004058837890625,
    0.0284423828125,
    0.0108642578125,
    -0.000873565673828125,
    -0.026123046875,
    0.002105712890625,
    -0.04443359375,
    0.02294921875,
    -0.029296875,
    -0.022216796875,
    -0.0026702880859375,
    0.000972747802734375,
    0.0380859375,
    -0.034423828125,
    -0.01171875,
    -0.004180908203125,
    0.0087890625,
    0.034423828125,
    -0.0244140625,
    0.0260009765625,
    0.01019287109375,
    -0.01446533203125,
    0.0189208984375,
    -0.0322265625,
    0.00860595703125,
    0.0103759765625,
    0.01904296875,
    -0.0054931640625,
    -0.004669189453125,
    0.0028228759765625,
    -0.016845703125,
    0.0017242431640625,
    -0.0125732421875,
    0.0308837890625,
    -0.016357421875,
    0.025634765625,
    0.0032196044921875,
    -0.0213623046875,
    0.0184326171875,
    0.004852294921875,
    -0.00836181640625,
    -0.00189971923828125,
    0.01385498046875,
    -0.055419921875,
    0.0458984375,
    -0.01171875,
    0.01385498046875,
    0.022705078125,
    0.0032806396484375,
    0.0031280517578125,
    -0.03564453125,
    -0.04296875,
    0.0179443359375,
    -0.0234375,
    -0.0224609375,
    0.0308837890625,
    0.0279541015625,
    0.005767822265625,
    0.007080078125,
    -0.00885009765625,
    -0.010498046875,
    0.025146484375,
    0.0038909912109375,
    -0.01055908203125,
    -0.021484375,
    -0.0234375,
    0.023681640625,
    -0.0069580078125,
    0.0079345703125,
    -0.048583984375,
    0.036865234375,
    0.031494140625,
    -0.004425048828125,
    -0.0306396484375,
    0.006866455078125,
    0.0008087158203125,
    0.01055908203125,
    0.03369140625,
    -0.0128173828125,
    -0.026123046875,
    -0.0478515625,
    -0.0206298828125,
    -0.00098419189453125,
    0.002593994140625,
    -0.0279541015625,
    0.004058837890625,
    0.03369140625,
    0.0185546875,
    -0.00689697265625,
    -0.0380859375,
    0.00921630859375,
    0.044189453125,
    -0.0186767578125,
    0.047119140625,
    0.000789642333984375,
    -0.03369140625,
    -0.000629425048828125,
    0.038818359375,
    -0.01953125,
    -0.002532958984375,
    0.00180816650390625,
    0.03369140625,
    -0.00592041015625,
    -0.03369140625,
    0.001983642578125,
    0.0101318359375,
    -0.02880859375,
    -0.002410888671875,
    0.01300048828125,
    -0.054443359375,
    -0.03759765625,
    0.0194091796875,
    -0.00238037109375,
    0.0240478515625,
    0.00049591064453125,
    0.026123046875,
    -0.0037994384765625,
    0.004638671875,
    0.0024566650390625,
    -0.0218505859375,
    -0.0000073909759521484375,
    -0.0140380859375,
    0.0185546875,
    0.0125732421875,
    0.0024871826171875,
    0.0118408203125,
    -0.010498046875,
    0.0257568359375,
    -0.00836181640625,
    -0.03369140625,
    -0.01513671875,
    -0.0047607421875,
    -0.0245361328125,
    0.04296875,
    0.01312255859375,
    0.039794921875,
    -0.008056640625,
    -0.006500244140625,
    -0.0242919921875,
    -0.004150390625,
    -0.048095703125,
    -0.016845703125,
    -0.0179443359375,
    0.0074462890625,
    -0.02490234375,
    0.0015869140625,
    -0.0208740234375,
    0.003631591796875,
    0.0234375,
    0.01373291015625,
    0.023193359375,
    -0.00093841552734375,
    -0.00592041015625,
    -0.0147705078125,
    0.0244140625,
    0.03662109375,
    -0.00738525390625,
    -0.01025390625,
    0.009521484375,
    -0.0234375,
    0.0260009765625,
    0.0211181640625,
    0.00482177734375,
    -0.006866455078125,
    0.00537109375,
    -0.0185546875,
    -0.01708984375,
    -0.01611328125,
    0.0002956390380859375,
    0.054931640625,
    -0.0042724609375,
    0.0260009765625,
    -0.0026702880859375,
    -0.0220947265625,
    -0.034912109375,
    0.0150146484375,
    -0.00006246566772460938,
    0.0029754638671875,
    0.028564453125,
    0.03857421875,
    -0.007598876953125,
    0.0135498046875,
    -0.0247802734375,
    0.046875,
    -0.0113525390625,
    0.00982666015625,
    -0.01422119140625,
    0.01361083984375,
    -0.01519775390625,
    0.0030975341796875,
    -0.0252685546875,
    -0.017578125,
    -0.01153564453125,
    -0.006927490234375,
    -0.0218505859375,
    0.0260009765625,
    -0.03564453125,
    -0.0101318359375,
    0.0123291015625,
    -0.006683349609375,
    -0.0018768310546875,
    -0.0252685546875,
    -0.0001583099365234375,
    -0.0020294189453125,
    -0.028564453125,
    0.00170135498046875,
    0.005340576171875,
    0.0198974609375,
    -0.00007104873657226562,
    -0.0007171630859375,
    -0.010498046875,
    -0.009033203125,
    -0.0194091796875,
    -0.032958984375,
    -0.01611328125,
    0.04833984375,
    -0.04150390625,
    -0.00021648406982421875,
    0.048828125,
    -0.017822265625,
    -0.006134033203125,
    0.0361328125,
    0.027587890625,
    0.037841796875,
    -0.035888671875,
    -0.0240478515625,
    -0.00408935546875,
    -0.000812530517578125,
    -0.0167236328125,
    0.005828857421875,
    0.03369140625,
    0.042236328125,
    0.0010833740234375,
    -0.022216796875,
    0.0224609375,
    -0.00225830078125,
    0.0281982421875,
    0.00506591796875,
    0.0087890625,
    -0.006591796875,
    0.00150299072265625,
    -0.02294921875,
    0.00008392333984375,
    -0.02783203125,
    -0.0252685546875,
    0.00101470947265625,
    -0.048583984375,
    -0.006744384765625,
    0.00677490234375,
    -0.0048828125,
    -0.0157470703125,
    0.018798828125,
    0.003936767578125,
    0.00193023681640625,
    -0.0380859375,
    -0.0147705078125,
    0.051025390625,
    0.00433349609375,
    0.033203125,
    -0.0233154296875,
    0.0341796875,
    -0.0169677734375,
    0.0218505859375,
    0.0091552734375,
    0.0211181640625,
    0.01318359375,
    0.003509521484375,
    0.01513671875,
    -0.0263671875,
    0.01068115234375,
    0.005584716796875,
    0.0004730224609375,
    -0.028564453125,
    -0.0556640625,
    0.0032196044921875,
    0.0206298828125,
    -0.040771484375,
    -0.033203125,
    0.01153564453125,
    -0.004150390625,
    -0.032470703125,
    0.0181884765625,
    0.002349853515625,
    -0.0111083984375,
    -0.006561279296875,
    -0.0194091796875,
    -0.02294921875,
    -0.005889892578125,
    -0.02001953125,
    0.010986328125,
    0.011962890625,
    -0.00128936767578125,
    -0.042236328125,
    0.0306396484375,
    0.011474609375,
    -0.0218505859375,
    0.0240478515625,
    -0.013427734375,
    0.0034637451171875,
    -0.026611328125,
    -0.01953125,
    0.0284423828125,
    0.02294921875,
    -0.02685546875,
    0.02197265625,
    -0.012939453125,
    0.0291748046875,
    0.0289306640625,
    -0.036376953125,
    0.042724609375,
    -0.009521484375,
    -0.0028076171875,
    0.024169921875,
    0.01068115234375,
    0.00092315673828125,
    0.033203125,
    0.037841796875,
    0.0003509521484375,
    -0.0087890625,
    0.000675201416015625,
    -0.01123046875,
    -0.0111083984375,
    0.0218505859375,
    0.01055908203125,
    0.01336669921875,
    -0.003173828125,
    0.01165771484375,
    -0.015869140625,
    -0.0027923583984375,
    0.02685546875,
    0.0169677734375,
    -0.002410888671875,
    0.033447265625,
    -0.0286865234375,
    0.01611328125,
    0.0302734375,
    0.013916015625,
    0.01708984375,
    0.0018310546875,
    0.003662109375,
    -0.0245361328125,
    0.014892578125,
    -0.0244140625,
    -0.000827789306640625,
    0.0177001953125,
    -0.01263427734375,
    0.0166015625,
    0.01397705078125,
    0.017333984375,
    -0.01385498046875,
    -0.05419921875,
    -0.0068359375,
    -0.0048828125,
    0.0017242431640625,
    0.01409912109375,
    0.01513671875,
    -0.002105712890625,
    -0.007171630859375,
    -0.01287841796875,
    -0.00147247314453125,
    0.0084228515625,
    -0.008056640625,
    -0.004638671875,
    -0.00019741058349609375,
    -0.06494140625,
    -0.00011730194091796875,
    0.01092529296875,
    0.0126953125,
    -0.050048828125,
    -0.0220947265625,
    -0.01177978515625,
    0.00640869140625,
    -0.03173828125,
    0.000659942626953125
  ],
  "created": "2025-06-12T05:14:14.234978",
  "count": 46
}